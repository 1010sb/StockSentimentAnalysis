{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595b75c1",
   "metadata": {},
   "source": [
    "## JSON File Sorter \n",
    "### Merging, Transforming, and Sorting JSON Files into a CSV\n",
    "- Streamlines the process of merging multiple JSON files within a specified folder.\n",
    "- Efficiently concatenates all JSON files into a single DataFrame.\n",
    "- Saves the merged data into a CSV file for easy access and analysis.\n",
    "- Transforms the timestamp data from seconds to the date format (dd-mm-yyyy) for improved readability and organization.\n",
    "- Provides enhanced sorting capabilities, ensuring dates are arranged in chronological order.\n",
    "- Simplifies the organization and processing of large amounts of JSON data.\n",
    "- Delivers a neatly structured CSV file, ready for further analysis or integration into other systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c9f9109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing JSON files: 100%|██████████| 3341/3341 [03:31<00:00, 15.77file/s]\n",
      "\n",
      "Processing JSON files:   0%|          | 4/3411 [00:00<01:32, 36.70file/s]\u001b[A\n",
      "Processing JSON files:   0%|          | 9/3411 [00:00<01:22, 41.18file/s]\u001b[A\n",
      "Processing JSON files:   0%|          | 14/3411 [00:00<01:21, 41.84file/s]\u001b[A\n",
      "Processing JSON files:   1%|          | 20/3411 [00:00<01:12, 46.60file/s]\u001b[A\n",
      "Processing JSON files:   1%|          | 25/3411 [00:00<01:11, 47.30file/s]\u001b[A\n",
      "Processing JSON files:   1%|          | 30/3411 [00:00<01:13, 45.89file/s]\u001b[A\n",
      "Processing JSON files:   1%|          | 35/3411 [00:00<01:18, 43.04file/s]\u001b[A\n",
      "Processing JSON files:   1%|          | 40/3411 [00:00<01:29, 37.82file/s]\u001b[A\n",
      "Processing JSON files:   1%|▏         | 47/3411 [00:01<01:14, 44.94file/s]\u001b[A\n",
      "Processing JSON files:   2%|▏         | 53/3411 [00:01<01:09, 48.12file/s]\u001b[A\n",
      "Processing JSON files:   2%|▏         | 59/3411 [00:01<01:06, 50.36file/s]\u001b[A\n",
      "Processing JSON files:   2%|▏         | 65/3411 [00:01<01:03, 52.73file/s]\u001b[A\n",
      "Processing JSON files:   2%|▏         | 71/3411 [00:01<01:05, 51.20file/s]\u001b[A\n",
      "Processing JSON files:   2%|▏         | 77/3411 [00:01<01:09, 47.69file/s]\u001b[A\n",
      "Processing JSON files:   2%|▏         | 82/3411 [00:01<01:33, 35.59file/s]\u001b[A\n",
      "Processing JSON files:   3%|▎         | 87/3411 [00:02<01:28, 37.54file/s]\u001b[A\n",
      "Processing JSON files:   3%|▎         | 92/3411 [00:02<01:32, 35.84file/s]\u001b[A\n",
      "Processing JSON files:   3%|▎         | 98/3411 [00:02<01:20, 40.95file/s]\u001b[A\n",
      "Processing JSON files:   3%|▎         | 104/3411 [00:02<01:16, 43.36file/s]\u001b[A\n",
      "Processing JSON files:   3%|▎         | 109/3411 [00:02<01:13, 44.70file/s]\u001b[A\n",
      "Processing JSON files:   3%|▎         | 114/3411 [00:02<01:19, 41.58file/s]\u001b[A\n",
      "Processing JSON files:   3%|▎         | 119/3411 [00:02<01:21, 40.63file/s]\u001b[A\n",
      "Processing JSON files:   4%|▎         | 124/3411 [00:02<01:22, 39.66file/s]\u001b[A\n",
      "Processing JSON files:   4%|▍         | 129/3411 [00:03<01:27, 37.48file/s]\u001b[A\n",
      "Processing JSON files:   4%|▍         | 134/3411 [00:03<01:21, 40.35file/s]\u001b[A\n",
      "Processing JSON files:   4%|▍         | 140/3411 [00:03<01:13, 44.80file/s]\u001b[A\n",
      "Processing JSON files:   4%|▍         | 145/3411 [00:03<01:13, 44.66file/s]\u001b[A\n",
      "Processing JSON files:   4%|▍         | 150/3411 [00:03<01:11, 45.31file/s]\u001b[A\n",
      "Processing JSON files:   5%|▍         | 155/3411 [00:03<01:16, 42.31file/s]\u001b[A\n",
      "Processing JSON files:   5%|▍         | 160/3411 [00:03<01:19, 40.85file/s]\u001b[A\n",
      "Processing JSON files:   5%|▍         | 165/3411 [00:03<01:19, 40.62file/s]\u001b[A\n",
      "Processing JSON files:   5%|▍         | 170/3411 [00:04<01:24, 38.41file/s]\u001b[A\n",
      "Processing JSON files:   5%|▌         | 174/3411 [00:04<01:30, 35.66file/s]\u001b[A\n",
      "Processing JSON files:   5%|▌         | 178/3411 [00:04<01:34, 34.34file/s]\u001b[A\n",
      "Processing JSON files:   5%|▌         | 182/3411 [00:04<01:36, 33.36file/s]\u001b[A\n",
      "Processing JSON files:   5%|▌         | 187/3411 [00:04<01:26, 37.21file/s]\u001b[A\n",
      "Processing JSON files:   6%|▌         | 191/3411 [00:04<01:26, 37.39file/s]\u001b[A\n",
      "Processing JSON files:   6%|▌         | 195/3411 [00:04<01:35, 33.54file/s]\u001b[A\n",
      "Processing JSON files:   6%|▌         | 200/3411 [00:04<01:28, 36.35file/s]\u001b[A\n",
      "Processing JSON files:   6%|▌         | 204/3411 [00:05<01:34, 33.90file/s]\u001b[A\n",
      "Processing JSON files:   6%|▌         | 208/3411 [00:05<01:34, 33.93file/s]\u001b[A\n",
      "Processing JSON files:   6%|▌         | 212/3411 [00:05<01:37, 32.87file/s]\u001b[A\n",
      "Processing JSON files:   6%|▋         | 216/3411 [00:05<01:35, 33.30file/s]\u001b[A\n",
      "Processing JSON files:   6%|▋         | 220/3411 [00:05<01:37, 32.68file/s]\u001b[A\n",
      "Processing JSON files:   7%|▋         | 224/3411 [00:05<01:40, 31.78file/s]\u001b[A\n",
      "Processing JSON files:   7%|▋         | 228/3411 [00:05<01:44, 30.43file/s]\u001b[A\n",
      "Processing JSON files:   7%|▋         | 232/3411 [00:05<01:44, 30.42file/s]\u001b[A\n",
      "Processing JSON files:   7%|▋         | 236/3411 [00:06<01:44, 30.47file/s]\u001b[A\n",
      "Processing JSON files:   7%|▋         | 240/3411 [00:06<01:42, 30.89file/s]\u001b[A\n",
      "Processing JSON files:   7%|▋         | 244/3411 [00:06<01:42, 30.84file/s]\u001b[A\n",
      "Processing JSON files:   7%|▋         | 248/3411 [00:06<01:36, 32.79file/s]\u001b[A\n",
      "Processing JSON files:   7%|▋         | 252/3411 [00:06<01:35, 33.20file/s]\u001b[A\n",
      "Processing JSON files:   8%|▊         | 256/3411 [00:06<01:33, 33.83file/s]\u001b[A\n",
      "Processing JSON files:   8%|▊         | 261/3411 [00:06<01:25, 36.86file/s]\u001b[A\n",
      "Processing JSON files:   8%|▊         | 265/3411 [00:06<01:23, 37.65file/s]\u001b[A\n",
      "Processing JSON files:   8%|▊         | 269/3411 [00:06<01:29, 35.08file/s]\u001b[A\n",
      "Processing JSON files:   8%|▊         | 273/3411 [00:07<01:30, 34.60file/s]\u001b[A\n",
      "Processing JSON files:   8%|▊         | 277/3411 [00:07<01:38, 31.78file/s]\u001b[A\n",
      "Processing JSON files:   8%|▊         | 281/3411 [00:07<01:35, 32.95file/s]\u001b[A\n",
      "Processing JSON files:   8%|▊         | 286/3411 [00:07<01:25, 36.37file/s]\u001b[A\n",
      "Processing JSON files:   9%|▊         | 290/3411 [00:07<01:29, 34.75file/s]\u001b[A\n",
      "Processing JSON files:   9%|▊         | 294/3411 [00:07<01:29, 34.90file/s]\u001b[A\n",
      "Processing JSON files:   9%|▊         | 298/3411 [00:07<01:29, 34.96file/s]\u001b[A\n",
      "Processing JSON files:   9%|▉         | 302/3411 [00:07<01:29, 34.64file/s]\u001b[A\n",
      "Processing JSON files:   9%|▉         | 306/3411 [00:08<01:28, 35.15file/s]\u001b[A\n",
      "Processing JSON files:   9%|▉         | 310/3411 [00:08<01:27, 35.24file/s]\u001b[A\n",
      "Processing JSON files:   9%|▉         | 314/3411 [00:08<01:26, 35.99file/s]\u001b[A\n",
      "Processing JSON files:   9%|▉         | 318/3411 [00:08<01:25, 36.21file/s]\u001b[A\n",
      "Processing JSON files:   9%|▉         | 322/3411 [00:08<01:23, 37.05file/s]\u001b[A\n",
      "Processing JSON files:  10%|▉         | 326/3411 [00:08<01:27, 35.41file/s]\u001b[A\n",
      "Processing JSON files:  10%|▉         | 331/3411 [00:08<01:20, 38.23file/s]\u001b[A\n",
      "Processing JSON files:  10%|▉         | 335/3411 [00:08<01:21, 37.56file/s]\u001b[A\n",
      "Processing JSON files:  10%|▉         | 339/3411 [00:08<01:23, 36.84file/s]\u001b[A\n",
      "Processing JSON files:  10%|█         | 343/3411 [00:09<01:25, 35.95file/s]\u001b[A\n",
      "Processing JSON files:  10%|█         | 347/3411 [00:09<01:23, 36.87file/s]\u001b[A\n",
      "Processing JSON files:  10%|█         | 351/3411 [00:09<01:25, 35.99file/s]\u001b[A\n",
      "Processing JSON files:  10%|█         | 355/3411 [00:09<01:23, 36.66file/s]\u001b[A\n",
      "Processing JSON files:  11%|█         | 359/3411 [00:09<01:21, 37.33file/s]\u001b[A\n",
      "Processing JSON files:  11%|█         | 364/3411 [00:09<01:16, 39.73file/s]\u001b[A\n",
      "Processing JSON files:  11%|█         | 368/3411 [00:09<01:22, 37.11file/s]\u001b[A\n",
      "Processing JSON files:  11%|█         | 372/3411 [00:09<01:20, 37.77file/s]\u001b[A\n",
      "Processing JSON files:  11%|█         | 376/3411 [00:09<01:28, 34.47file/s]\u001b[A\n",
      "Processing JSON files:  11%|█         | 380/3411 [00:10<01:37, 31.21file/s]\u001b[A\n",
      "Processing JSON files:  11%|█▏        | 385/3411 [00:10<01:25, 35.19file/s]\u001b[A\n",
      "Processing JSON files:  11%|█▏        | 389/3411 [00:10<01:29, 33.89file/s]\u001b[A\n",
      "Processing JSON files:  12%|█▏        | 393/3411 [00:10<01:32, 32.70file/s]\u001b[A\n",
      "Processing JSON files:  12%|█▏        | 399/3411 [00:10<01:18, 38.57file/s]\u001b[A\n",
      "Processing JSON files:  12%|█▏        | 403/3411 [00:10<01:25, 35.13file/s]\u001b[A\n",
      "Processing JSON files:  12%|█▏        | 408/3411 [00:10<01:18, 38.20file/s]\u001b[A\n",
      "Processing JSON files:  12%|█▏        | 413/3411 [00:10<01:14, 40.46file/s]\u001b[A\n",
      "Processing JSON files:  12%|█▏        | 418/3411 [00:11<01:11, 42.05file/s]\u001b[A\n",
      "Processing JSON files:  12%|█▏        | 423/3411 [00:11<01:22, 36.04file/s]\u001b[A\n",
      "Processing JSON files:  13%|█▎        | 427/3411 [00:11<01:22, 36.31file/s]\u001b[A\n",
      "Processing JSON files:  13%|█▎        | 432/3411 [00:11<01:21, 36.55file/s]\u001b[A\n",
      "Processing JSON files:  13%|█▎        | 436/3411 [00:11<01:24, 35.19file/s]\u001b[A\n",
      "Processing JSON files:  13%|█▎        | 440/3411 [00:11<01:23, 35.61file/s]\u001b[A\n",
      "Processing JSON files:  13%|█▎        | 444/3411 [00:11<01:23, 35.60file/s]\u001b[A\n",
      "Processing JSON files:  13%|█▎        | 448/3411 [00:11<01:26, 34.24file/s]\u001b[A\n",
      "Processing JSON files:  13%|█▎        | 453/3411 [00:12<01:18, 37.89file/s]\u001b[A\n",
      "Processing JSON files:  13%|█▎        | 457/3411 [00:12<01:18, 37.87file/s]\u001b[A\n",
      "Processing JSON files:  14%|█▎        | 461/3411 [00:12<01:20, 36.53file/s]\u001b[A\n",
      "Processing JSON files:  14%|█▎        | 466/3411 [00:12<01:17, 37.77file/s]\u001b[A\n",
      "Processing JSON files:  14%|█▍        | 470/3411 [00:12<01:17, 38.19file/s]\u001b[A\n",
      "Processing JSON files:  14%|█▍        | 474/3411 [00:12<01:17, 37.81file/s]\u001b[A\n",
      "Processing JSON files:  14%|█▍        | 479/3411 [00:12<01:16, 38.53file/s]\u001b[A\n",
      "Processing JSON files:  14%|█▍        | 483/3411 [00:12<01:18, 37.30file/s]\u001b[A\n",
      "Processing JSON files:  14%|█▍        | 488/3411 [00:13<01:16, 38.46file/s]\u001b[A\n",
      "Processing JSON files:  14%|█▍        | 493/3411 [00:13<01:10, 41.40file/s]\u001b[A\n",
      "Processing JSON files:  15%|█▍        | 498/3411 [00:13<01:08, 42.41file/s]\u001b[A\n",
      "Processing JSON files:  15%|█▍        | 503/3411 [00:13<01:10, 41.33file/s]\u001b[A\n",
      "Processing JSON files:  15%|█▍        | 508/3411 [00:13<01:10, 41.28file/s]\u001b[A\n",
      "Processing JSON files:  15%|█▌        | 513/3411 [00:13<01:15, 38.57file/s]\u001b[A\n",
      "Processing JSON files:  15%|█▌        | 517/3411 [00:13<01:18, 37.03file/s]\u001b[A\n",
      "Processing JSON files:  15%|█▌        | 523/3411 [00:13<01:09, 41.40file/s]\u001b[A\n",
      "Processing JSON files:  15%|█▌        | 528/3411 [00:13<01:09, 41.75file/s]\u001b[A\n",
      "Processing JSON files:  16%|█▌        | 533/3411 [00:14<01:06, 43.19file/s]\u001b[A\n",
      "Processing JSON files:  16%|█▌        | 539/3411 [00:14<01:01, 46.96file/s]\u001b[A\n",
      "Processing JSON files:  16%|█▌        | 544/3411 [00:14<01:04, 44.57file/s]\u001b[A\n",
      "Processing JSON files:  16%|█▌        | 549/3411 [00:14<01:05, 43.66file/s]\u001b[A\n",
      "Processing JSON files:  16%|█▌        | 554/3411 [00:14<01:06, 42.92file/s]\u001b[A\n",
      "Processing JSON files:  16%|█▋        | 560/3411 [00:14<01:02, 45.61file/s]\u001b[A\n",
      "Processing JSON files:  17%|█▋        | 566/3411 [00:14<00:58, 48.90file/s]\u001b[A\n",
      "Processing JSON files:  17%|█▋        | 571/3411 [00:14<00:58, 48.48file/s]\u001b[A\n",
      "Processing JSON files:  17%|█▋        | 576/3411 [00:15<01:04, 44.08file/s]\u001b[A\n",
      "Processing JSON files:  17%|█▋        | 581/3411 [00:15<01:04, 43.64file/s]\u001b[A\n",
      "Processing JSON files:  17%|█▋        | 586/3411 [00:15<01:04, 43.55file/s]\u001b[A\n",
      "Processing JSON files:  17%|█▋        | 591/3411 [00:15<01:03, 44.25file/s]\u001b[A\n",
      "Processing JSON files:  17%|█▋        | 596/3411 [00:15<01:06, 42.28file/s]\u001b[A\n",
      "Processing JSON files:  18%|█▊        | 601/3411 [00:15<01:03, 44.07file/s]\u001b[A\n",
      "Processing JSON files:  18%|█▊        | 606/3411 [00:15<01:03, 44.27file/s]\u001b[A\n",
      "Processing JSON files:  18%|█▊        | 611/3411 [00:15<01:02, 45.12file/s]\u001b[A\n",
      "Processing JSON files:  18%|█▊        | 616/3411 [00:15<01:02, 44.93file/s]\u001b[A\n",
      "Processing JSON files:  18%|█▊        | 622/3411 [00:16<00:59, 47.06file/s]\u001b[A\n",
      "Processing JSON files:  18%|█▊        | 627/3411 [00:16<01:04, 43.26file/s]\u001b[A\n",
      "Processing JSON files:  19%|█▊        | 633/3411 [00:16<00:59, 46.42file/s]\u001b[A\n",
      "Processing JSON files:  19%|█▊        | 638/3411 [00:16<00:58, 47.12file/s]\u001b[A\n",
      "Processing JSON files:  19%|█▉        | 643/3411 [00:16<01:00, 45.58file/s]\u001b[A\n",
      "Processing JSON files:  19%|█▉        | 648/3411 [00:16<01:05, 42.46file/s]\u001b[A\n",
      "Processing JSON files:  19%|█▉        | 653/3411 [00:16<01:06, 41.28file/s]\u001b[A\n",
      "Processing JSON files:  19%|█▉        | 659/3411 [00:16<01:01, 45.11file/s]\u001b[A\n",
      "Processing JSON files:  20%|█▉        | 666/3411 [00:17<00:55, 49.08file/s]\u001b[A\n",
      "Processing JSON files:  20%|█▉        | 673/3411 [00:17<00:50, 54.25file/s]\u001b[A\n",
      "Processing JSON files:  20%|█▉        | 679/3411 [00:17<00:53, 51.19file/s]\u001b[A\n",
      "Processing JSON files:  20%|██        | 685/3411 [00:17<00:55, 49.28file/s]\u001b[A\n",
      "Processing JSON files:  20%|██        | 691/3411 [00:17<00:59, 45.87file/s]\u001b[A\n",
      "Processing JSON files:  20%|██        | 697/3411 [00:17<00:57, 47.28file/s]\u001b[A\n",
      "Processing JSON files:  21%|██        | 702/3411 [00:17<00:59, 45.29file/s]\u001b[A\n",
      "Processing JSON files:  21%|██        | 708/3411 [00:17<00:56, 48.01file/s]\u001b[A\n",
      "Processing JSON files:  21%|██        | 713/3411 [00:17<00:58, 46.04file/s]\u001b[A\n",
      "Processing JSON files:  21%|██        | 719/3411 [00:18<00:56, 47.69file/s]\u001b[A\n",
      "Processing JSON files:  21%|██        | 724/3411 [00:18<00:56, 47.97file/s]\u001b[A\n",
      "Processing JSON files:  21%|██▏       | 729/3411 [00:18<00:58, 46.13file/s]\u001b[A\n",
      "Processing JSON files:  22%|██▏       | 734/3411 [00:18<01:01, 43.46file/s]\u001b[A\n",
      "Processing JSON files:  22%|██▏       | 740/3411 [00:18<00:56, 47.64file/s]\u001b[A\n",
      "Processing JSON files:  22%|██▏       | 746/3411 [00:18<00:52, 50.62file/s]\u001b[A\n",
      "Processing JSON files:  22%|██▏       | 752/3411 [00:18<00:50, 52.98file/s]\u001b[A\n",
      "Processing JSON files:  22%|██▏       | 758/3411 [00:18<00:49, 53.09file/s]\u001b[A\n",
      "Processing JSON files:  22%|██▏       | 764/3411 [00:18<00:48, 54.86file/s]\u001b[A\n",
      "Processing JSON files:  23%|██▎       | 770/3411 [00:19<00:51, 50.90file/s]\u001b[A\n",
      "Processing JSON files:  23%|██▎       | 776/3411 [00:19<00:53, 49.43file/s]\u001b[A\n",
      "Processing JSON files:  23%|██▎       | 782/3411 [00:19<00:55, 47.50file/s]\u001b[A\n",
      "Processing JSON files:  23%|██▎       | 787/3411 [00:19<01:03, 41.24file/s]\u001b[A\n",
      "Processing JSON files:  23%|██▎       | 792/3411 [00:19<01:03, 41.39file/s]\u001b[A\n",
      "Processing JSON files:  23%|██▎       | 797/3411 [00:19<01:02, 41.82file/s]\u001b[A\n",
      "Processing JSON files:  24%|██▎       | 803/3411 [00:19<00:56, 45.88file/s]\u001b[A\n",
      "Processing JSON files:  24%|██▎       | 808/3411 [00:20<00:59, 43.97file/s]\u001b[A\n",
      "Processing JSON files:  24%|██▍       | 813/3411 [00:20<01:04, 40.13file/s]\u001b[A\n",
      "Processing JSON files:  24%|██▍       | 818/3411 [00:20<01:01, 42.03file/s]\u001b[A\n",
      "Processing JSON files:  24%|██▍       | 823/3411 [00:20<01:03, 40.60file/s]\u001b[A\n",
      "Processing JSON files:  24%|██▍       | 828/3411 [00:20<01:12, 35.84file/s]\u001b[A\n",
      "Processing JSON files:  24%|██▍       | 833/3411 [00:20<01:07, 38.01file/s]\u001b[A\n",
      "Processing JSON files:  25%|██▍       | 837/3411 [00:20<01:09, 37.08file/s]\u001b[A\n",
      "Processing JSON files:  25%|██▍       | 841/3411 [00:20<01:09, 37.18file/s]\u001b[A\n",
      "Processing JSON files:  25%|██▍       | 847/3411 [00:21<01:00, 42.09file/s]\u001b[A\n",
      "Processing JSON files:  25%|██▍       | 852/3411 [00:21<00:58, 43.42file/s]\u001b[A\n",
      "Processing JSON files:  25%|██▌       | 857/3411 [00:21<01:02, 40.96file/s]\u001b[A\n",
      "Processing JSON files:  25%|██▌       | 862/3411 [00:21<01:13, 34.53file/s]\u001b[A\n",
      "Processing JSON files:  25%|██▌       | 866/3411 [00:21<01:19, 32.15file/s]\u001b[A\n",
      "Processing JSON files:  26%|██▌       | 870/3411 [00:21<01:26, 29.34file/s]\u001b[A\n",
      "Processing JSON files:  26%|██▌       | 874/3411 [00:21<01:20, 31.33file/s]\u001b[A\n",
      "Processing JSON files:  26%|██▌       | 878/3411 [00:22<01:17, 32.82file/s]\u001b[A\n",
      "Processing JSON files:  26%|██▌       | 882/3411 [00:22<01:17, 32.54file/s]\u001b[A\n",
      "Processing JSON files:  26%|██▌       | 887/3411 [00:22<01:10, 36.00file/s]\u001b[A\n",
      "Processing JSON files:  26%|██▌       | 892/3411 [00:22<01:04, 39.16file/s]\u001b[A\n",
      "Processing JSON files:  26%|██▋       | 897/3411 [00:22<01:07, 37.50file/s]\u001b[A\n",
      "Processing JSON files:  26%|██▋       | 901/3411 [00:22<01:11, 35.10file/s]\u001b[A\n",
      "Processing JSON files:  27%|██▋       | 905/3411 [00:22<01:12, 34.56file/s]\u001b[A\n",
      "Processing JSON files:  27%|██▋       | 910/3411 [00:22<01:08, 36.58file/s]\u001b[A\n",
      "Processing JSON files:  27%|██▋       | 914/3411 [00:22<01:08, 36.29file/s]\u001b[A\n",
      "Processing JSON files:  27%|██▋       | 919/3411 [00:23<01:03, 39.20file/s]\u001b[A\n",
      "Processing JSON files:  27%|██▋       | 924/3411 [00:23<00:59, 41.91file/s]\u001b[A\n",
      "Processing JSON files:  27%|██▋       | 930/3411 [00:23<00:54, 45.37file/s]\u001b[A\n",
      "Processing JSON files:  27%|██▋       | 935/3411 [00:23<00:56, 43.87file/s]\u001b[A\n",
      "Processing JSON files:  28%|██▊       | 940/3411 [00:23<01:01, 40.30file/s]\u001b[A\n",
      "Processing JSON files:  28%|██▊       | 945/3411 [00:23<00:58, 41.87file/s]\u001b[A\n",
      "Processing JSON files:  28%|██▊       | 950/3411 [00:23<01:03, 38.90file/s]\u001b[A\n",
      "Processing JSON files:  28%|██▊       | 955/3411 [00:23<01:03, 38.95file/s]\u001b[A\n",
      "Processing JSON files:  28%|██▊       | 960/3411 [00:24<00:59, 41.38file/s]\u001b[A\n",
      "Processing JSON files:  28%|██▊       | 966/3411 [00:24<00:53, 45.76file/s]\u001b[A\n",
      "Processing JSON files:  28%|██▊       | 971/3411 [00:24<00:55, 43.73file/s]\u001b[A\n",
      "Processing JSON files:  29%|██▊       | 976/3411 [00:24<00:53, 45.16file/s]\u001b[A\n",
      "Processing JSON files:  29%|██▉       | 981/3411 [00:24<00:52, 46.04file/s]\u001b[A\n",
      "Processing JSON files:  29%|██▉       | 986/3411 [00:24<00:55, 43.51file/s]\u001b[A\n",
      "Processing JSON files:  29%|██▉       | 992/3411 [00:24<00:53, 45.10file/s]\u001b[A\n",
      "Processing JSON files:  29%|██▉       | 998/3411 [00:24<00:51, 46.53file/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files:  29%|██▉       | 1003/3411 [00:24<00:51, 46.40file/s]\u001b[A\n",
      "Processing JSON files:  30%|██▉       | 1008/3411 [00:25<00:52, 45.53file/s]\u001b[A\n",
      "Processing JSON files:  30%|██▉       | 1013/3411 [00:25<00:53, 44.46file/s]\u001b[A\n",
      "Processing JSON files:  30%|██▉       | 1018/3411 [00:25<00:52, 45.77file/s]\u001b[A\n",
      "Processing JSON files:  30%|███       | 1024/3411 [00:25<00:50, 47.28file/s]\u001b[A\n",
      "Processing JSON files:  30%|███       | 1030/3411 [00:25<00:47, 49.99file/s]\u001b[A\n",
      "Processing JSON files:  30%|███       | 1036/3411 [00:25<00:49, 48.04file/s]\u001b[A\n",
      "Processing JSON files:  31%|███       | 1041/3411 [00:25<00:50, 46.71file/s]\u001b[A\n",
      "Processing JSON files:  31%|███       | 1047/3411 [00:25<00:47, 50.13file/s]\u001b[A\n",
      "Processing JSON files:  31%|███       | 1053/3411 [00:25<00:45, 52.39file/s]\u001b[A\n",
      "Processing JSON files:  31%|███       | 1059/3411 [00:26<00:46, 50.43file/s]\u001b[A\n",
      "Processing JSON files:  31%|███       | 1065/3411 [00:26<00:47, 49.37file/s]\u001b[A\n",
      "Processing JSON files:  31%|███▏      | 1070/3411 [00:26<00:49, 47.26file/s]\u001b[A\n",
      "Processing JSON files:  32%|███▏      | 1076/3411 [00:26<00:46, 49.76file/s]\u001b[A\n",
      "Processing JSON files:  32%|███▏      | 1082/3411 [00:26<00:45, 51.02file/s]\u001b[A\n",
      "Processing JSON files:  32%|███▏      | 1088/3411 [00:26<00:43, 52.83file/s]\u001b[A\n",
      "Processing JSON files:  32%|███▏      | 1095/3411 [00:26<00:41, 56.04file/s]\u001b[A\n",
      "Processing JSON files:  32%|███▏      | 1101/3411 [00:26<00:41, 56.28file/s]\u001b[A\n",
      "Processing JSON files:  32%|███▏      | 1107/3411 [00:27<00:44, 51.69file/s]\u001b[A\n",
      "Processing JSON files:  33%|███▎      | 1113/3411 [00:27<00:43, 53.04file/s]\u001b[A\n",
      "Processing JSON files:  33%|███▎      | 1119/3411 [00:27<00:42, 53.83file/s]\u001b[A\n",
      "Processing JSON files:  33%|███▎      | 1125/3411 [00:27<00:42, 53.31file/s]\u001b[A\n",
      "Processing JSON files:  33%|███▎      | 1131/3411 [00:27<00:45, 50.09file/s]\u001b[A\n",
      "Processing JSON files:  33%|███▎      | 1137/3411 [00:27<00:48, 47.34file/s]\u001b[A\n",
      "Processing JSON files:  33%|███▎      | 1142/3411 [00:27<00:47, 47.61file/s]\u001b[A\n",
      "Processing JSON files:  34%|███▎      | 1147/3411 [00:27<00:51, 44.35file/s]\u001b[A\n",
      "Processing JSON files:  34%|███▍      | 1152/3411 [00:28<00:53, 42.19file/s]\u001b[A\n",
      "Processing JSON files:  34%|███▍      | 1157/3411 [00:28<00:55, 40.48file/s]\u001b[A\n",
      "Processing JSON files:  34%|███▍      | 1163/3411 [00:28<00:50, 44.33file/s]\u001b[A\n",
      "Processing JSON files:  34%|███▍      | 1170/3411 [00:28<00:45, 49.24file/s]\u001b[A\n",
      "Processing JSON files:  35%|███▍      | 1177/3411 [00:28<00:42, 53.07file/s]\u001b[A\n",
      "Processing JSON files:  35%|███▍      | 1183/3411 [00:28<00:40, 54.41file/s]\u001b[A\n",
      "Processing JSON files:  35%|███▍      | 1189/3411 [00:28<00:41, 53.27file/s]\u001b[A\n",
      "Processing JSON files:  35%|███▌      | 1195/3411 [00:28<00:43, 50.63file/s]\u001b[A\n",
      "Processing JSON files:  35%|███▌      | 1201/3411 [00:28<00:46, 47.80file/s]\u001b[A\n",
      "Processing JSON files:  35%|███▌      | 1207/3411 [00:29<00:45, 48.48file/s]\u001b[A\n",
      "Processing JSON files:  36%|███▌      | 1212/3411 [00:29<00:46, 47.50file/s]\u001b[A\n",
      "Processing JSON files:  36%|███▌      | 1217/3411 [00:29<00:48, 45.57file/s]\u001b[A\n",
      "Processing JSON files:  36%|███▌      | 1223/3411 [00:29<00:45, 48.29file/s]\u001b[A\n",
      "Processing JSON files:  36%|███▌      | 1228/3411 [00:29<00:46, 46.69file/s]\u001b[A\n",
      "Processing JSON files:  36%|███▌      | 1233/3411 [00:29<00:46, 46.60file/s]\u001b[A\n",
      "Processing JSON files:  36%|███▋      | 1238/3411 [00:29<00:52, 41.30file/s]\u001b[A\n",
      "Processing JSON files:  36%|███▋      | 1245/3411 [00:29<00:45, 47.30file/s]\u001b[A\n",
      "Processing JSON files:  37%|███▋      | 1251/3411 [00:30<00:44, 48.95file/s]\u001b[A\n",
      "Processing JSON files:  37%|███▋      | 1257/3411 [00:30<00:42, 50.86file/s]\u001b[A\n",
      "Processing JSON files:  37%|███▋      | 1264/3411 [00:30<00:38, 55.97file/s]\u001b[A\n",
      "Processing JSON files:  37%|███▋      | 1270/3411 [00:30<00:38, 55.79file/s]\u001b[A\n",
      "Processing JSON files:  37%|███▋      | 1276/3411 [00:30<00:42, 50.12file/s]\u001b[A\n",
      "Processing JSON files:  38%|███▊      | 1282/3411 [00:30<00:42, 50.14file/s]\u001b[A\n",
      "Processing JSON files:  38%|███▊      | 1288/3411 [00:30<00:43, 48.73file/s]\u001b[A\n",
      "Processing JSON files:  38%|███▊      | 1293/3411 [00:30<00:44, 47.76file/s]\u001b[A\n",
      "Processing JSON files:  38%|███▊      | 1299/3411 [00:30<00:41, 50.86file/s]\u001b[A\n",
      "Processing JSON files:  38%|███▊      | 1305/3411 [00:31<00:39, 52.90file/s]\u001b[A\n",
      "Processing JSON files:  38%|███▊      | 1311/3411 [00:31<00:42, 49.41file/s]\u001b[A\n",
      "Processing JSON files:  39%|███▊      | 1317/3411 [00:31<00:43, 47.83file/s]\u001b[A\n",
      "Processing JSON files:  39%|███▉      | 1322/3411 [00:31<00:44, 46.84file/s]\u001b[A\n",
      "Processing JSON files:  39%|███▉      | 1327/3411 [00:31<00:46, 45.19file/s]\u001b[A\n",
      "Processing JSON files:  39%|███▉      | 1333/3411 [00:31<00:44, 47.18file/s]\u001b[A\n",
      "Processing JSON files:  39%|███▉      | 1339/3411 [00:31<00:42, 49.27file/s]\u001b[A\n",
      "Processing JSON files:  39%|███▉      | 1345/3411 [00:31<00:39, 52.01file/s]\u001b[A\n",
      "Processing JSON files:  40%|███▉      | 1351/3411 [00:32<00:41, 49.95file/s]\u001b[A\n",
      "Processing JSON files:  40%|███▉      | 1358/3411 [00:32<00:39, 52.05file/s]\u001b[A\n",
      "Processing JSON files:  40%|███▉      | 1364/3411 [00:32<00:42, 48.48file/s]\u001b[A\n",
      "Processing JSON files:  40%|████      | 1369/3411 [00:32<00:42, 47.70file/s]\u001b[A\n",
      "Processing JSON files:  40%|████      | 1374/3411 [00:32<00:43, 47.00file/s]\u001b[A\n",
      "Processing JSON files:  40%|████      | 1379/3411 [00:32<00:48, 41.88file/s]\u001b[A\n",
      "Processing JSON files:  41%|████      | 1384/3411 [00:32<00:52, 38.51file/s]\u001b[A\n",
      "Processing JSON files:  41%|████      | 1389/3411 [00:32<00:51, 39.16file/s]\u001b[A\n",
      "Processing JSON files:  41%|████      | 1394/3411 [00:33<00:51, 39.12file/s]\u001b[A\n",
      "Processing JSON files:  41%|████      | 1398/3411 [00:33<00:51, 38.90file/s]\u001b[A\n",
      "Processing JSON files:  41%|████      | 1402/3411 [00:33<00:56, 35.85file/s]\u001b[A\n",
      "Processing JSON files:  41%|████      | 1406/3411 [00:33<00:55, 35.95file/s]\u001b[A\n",
      "Processing JSON files:  41%|████▏     | 1410/3411 [00:33<00:57, 34.74file/s]\u001b[A\n",
      "Processing JSON files:  41%|████▏     | 1415/3411 [00:33<00:54, 36.87file/s]\u001b[A\n",
      "Processing JSON files:  42%|████▏     | 1420/3411 [00:33<00:54, 36.61file/s]\u001b[A\n",
      "Processing JSON files:  42%|████▏     | 1426/3411 [00:33<00:48, 41.08file/s]\u001b[A\n",
      "Processing JSON files:  42%|████▏     | 1432/3411 [00:34<00:44, 44.80file/s]\u001b[A\n",
      "Processing JSON files:  42%|████▏     | 1437/3411 [00:34<00:43, 45.28file/s]\u001b[A\n",
      "Processing JSON files:  42%|████▏     | 1442/3411 [00:34<00:47, 41.46file/s]\u001b[A\n",
      "Processing JSON files:  42%|████▏     | 1447/3411 [00:34<00:48, 40.27file/s]\u001b[A\n",
      "Processing JSON files:  43%|████▎     | 1452/3411 [00:34<00:50, 38.60file/s]\u001b[A\n",
      "Processing JSON files:  43%|████▎     | 1456/3411 [00:34<00:57, 34.02file/s]\u001b[A\n",
      "Processing JSON files:  43%|████▎     | 1460/3411 [00:34<00:56, 34.50file/s]\u001b[A\n",
      "Processing JSON files:  43%|████▎     | 1464/3411 [00:34<00:56, 34.45file/s]\u001b[A\n",
      "Processing JSON files:  43%|████▎     | 1468/3411 [00:35<00:57, 34.08file/s]\u001b[A\n",
      "Processing JSON files:  43%|████▎     | 1472/3411 [00:35<00:56, 34.26file/s]\u001b[A\n",
      "Processing JSON files:  43%|████▎     | 1476/3411 [00:35<01:23, 23.13file/s]\u001b[A\n",
      "Processing JSON files:  43%|████▎     | 1480/3411 [00:35<01:16, 25.16file/s]\u001b[A\n",
      "Processing JSON files:  43%|████▎     | 1483/3411 [00:35<01:14, 25.96file/s]\u001b[A\n",
      "Processing JSON files:  44%|████▎     | 1487/3411 [00:35<01:09, 27.79file/s]\u001b[A\n",
      "Processing JSON files:  44%|████▎     | 1492/3411 [00:35<01:00, 31.60file/s]\u001b[A\n",
      "Processing JSON files:  44%|████▍     | 1497/3411 [00:36<00:54, 34.88file/s]\u001b[A\n",
      "Processing JSON files:  44%|████▍     | 1502/3411 [00:36<00:49, 38.59file/s]\u001b[A\n",
      "Processing JSON files:  44%|████▍     | 1507/3411 [00:36<00:51, 36.75file/s]\u001b[A\n",
      "Processing JSON files:  44%|████▍     | 1512/3411 [00:36<00:47, 39.98file/s]\u001b[A\n",
      "Processing JSON files:  44%|████▍     | 1517/3411 [00:36<00:49, 38.60file/s]\u001b[A\n",
      "Processing JSON files:  45%|████▍     | 1521/3411 [00:36<00:52, 36.35file/s]\u001b[A\n",
      "Processing JSON files:  45%|████▍     | 1525/3411 [00:36<00:56, 33.09file/s]\u001b[A\n",
      "Processing JSON files:  45%|████▍     | 1529/3411 [00:37<00:59, 31.61file/s]\u001b[A\n",
      "Processing JSON files:  45%|████▍     | 1533/3411 [00:37<00:58, 32.28file/s]\u001b[A\n",
      "Processing JSON files:  45%|████▌     | 1538/3411 [00:37<00:54, 34.43file/s]\u001b[A\n",
      "Processing JSON files:  45%|████▌     | 1542/3411 [00:37<00:52, 35.63file/s]\u001b[A\n",
      "Processing JSON files:  45%|████▌     | 1546/3411 [00:37<00:54, 34.44file/s]\u001b[A\n",
      "Processing JSON files:  45%|████▌     | 1550/3411 [00:37<00:59, 31.49file/s]\u001b[A\n",
      "Processing JSON files:  46%|████▌     | 1554/3411 [00:37<01:01, 29.97file/s]\u001b[A\n",
      "Processing JSON files:  46%|████▌     | 1558/3411 [00:37<01:01, 30.09file/s]\u001b[A\n",
      "Processing JSON files:  46%|████▌     | 1562/3411 [00:38<00:58, 31.35file/s]\u001b[A\n",
      "Processing JSON files:  46%|████▌     | 1567/3411 [00:38<00:53, 34.79file/s]\u001b[A\n",
      "Processing JSON files:  46%|████▌     | 1572/3411 [00:38<00:49, 36.89file/s]\u001b[A\n",
      "Processing JSON files:  46%|████▋     | 1578/3411 [00:38<00:44, 41.35file/s]\u001b[A\n",
      "Processing JSON files:  46%|████▋     | 1585/3411 [00:38<00:38, 47.34file/s]\u001b[A\n",
      "Processing JSON files:  47%|████▋     | 1590/3411 [00:38<00:40, 45.21file/s]\u001b[A\n",
      "Processing JSON files:  47%|████▋     | 1596/3411 [00:38<00:39, 45.52file/s]\u001b[A\n",
      "Processing JSON files:  47%|████▋     | 1601/3411 [00:38<00:39, 45.82file/s]\u001b[A\n",
      "Processing JSON files:  47%|████▋     | 1606/3411 [00:38<00:42, 42.18file/s]\u001b[A\n",
      "Processing JSON files:  47%|████▋     | 1611/3411 [00:39<00:42, 42.84file/s]\u001b[A\n",
      "Processing JSON files:  47%|████▋     | 1617/3411 [00:39<00:39, 45.59file/s]\u001b[A\n",
      "Processing JSON files:  48%|████▊     | 1622/3411 [00:39<00:39, 44.96file/s]\u001b[A\n",
      "Processing JSON files:  48%|████▊     | 1627/3411 [00:39<00:38, 45.87file/s]\u001b[A\n",
      "Processing JSON files:  48%|████▊     | 1633/3411 [00:39<00:35, 49.51file/s]\u001b[A\n",
      "Processing JSON files:  48%|████▊     | 1640/3411 [00:39<00:32, 54.09file/s]\u001b[A\n",
      "Processing JSON files:  48%|████▊     | 1646/3411 [00:39<00:32, 54.41file/s]\u001b[A\n",
      "Processing JSON files:  48%|████▊     | 1652/3411 [00:39<00:34, 50.41file/s]\u001b[A\n",
      "Processing JSON files:  49%|████▊     | 1658/3411 [00:40<00:34, 50.27file/s]\u001b[A\n",
      "Processing JSON files:  49%|████▉     | 1664/3411 [00:40<00:33, 51.75file/s]\u001b[A\n",
      "Processing JSON files:  49%|████▉     | 1672/3411 [00:40<00:30, 57.53file/s]\u001b[A\n",
      "Processing JSON files:  49%|████▉     | 1678/3411 [00:40<00:32, 53.50file/s]\u001b[A\n",
      "Processing JSON files:  49%|████▉     | 1684/3411 [00:40<00:31, 54.10file/s]\u001b[A\n",
      "Processing JSON files:  50%|████▉     | 1690/3411 [00:40<00:31, 55.12file/s]\u001b[A\n",
      "Processing JSON files:  50%|████▉     | 1696/3411 [00:40<00:30, 56.30file/s]\u001b[A\n",
      "Processing JSON files:  50%|████▉     | 1702/3411 [00:40<00:30, 55.46file/s]\u001b[A\n",
      "Processing JSON files:  50%|█████     | 1708/3411 [00:40<00:31, 53.65file/s]\u001b[A\n",
      "Processing JSON files:  50%|█████     | 1714/3411 [00:41<00:34, 49.45file/s]\u001b[A\n",
      "Processing JSON files:  50%|█████     | 1720/3411 [00:41<00:32, 51.76file/s]\u001b[A\n",
      "Processing JSON files:  51%|█████     | 1727/3411 [00:41<00:29, 56.22file/s]\u001b[A\n",
      "Processing JSON files:  51%|█████     | 1733/3411 [00:41<00:30, 54.62file/s]\u001b[A\n",
      "Processing JSON files:  51%|█████     | 1739/3411 [00:41<00:30, 54.92file/s]\u001b[A\n",
      "Processing JSON files:  51%|█████     | 1745/3411 [00:41<00:30, 55.26file/s]\u001b[A\n",
      "Processing JSON files:  51%|█████▏    | 1751/3411 [00:41<00:30, 54.62file/s]\u001b[A\n",
      "Processing JSON files:  52%|█████▏    | 1757/3411 [00:41<00:30, 55.01file/s]\u001b[A\n",
      "Processing JSON files:  52%|█████▏    | 1764/3411 [00:41<00:28, 58.04file/s]\u001b[A\n",
      "Processing JSON files:  52%|█████▏    | 1770/3411 [00:42<00:32, 50.26file/s]\u001b[A\n",
      "Processing JSON files:  52%|█████▏    | 1776/3411 [00:42<00:31, 52.65file/s]\u001b[A\n",
      "Processing JSON files:  52%|█████▏    | 1784/3411 [00:42<00:28, 57.77file/s]\u001b[A\n",
      "Processing JSON files:  52%|█████▏    | 1790/3411 [00:42<00:28, 57.21file/s]\u001b[A\n",
      "Processing JSON files:  53%|█████▎    | 1796/3411 [00:42<00:29, 55.49file/s]\u001b[A\n",
      "Processing JSON files:  53%|█████▎    | 1802/3411 [00:42<00:29, 55.13file/s]\u001b[A\n",
      "Processing JSON files:  53%|█████▎    | 1808/3411 [00:42<00:31, 50.75file/s]\u001b[A\n",
      "Processing JSON files:  53%|█████▎    | 1814/3411 [00:42<00:31, 51.50file/s]\u001b[A\n",
      "Processing JSON files:  53%|█████▎    | 1820/3411 [00:42<00:30, 52.18file/s]\u001b[A\n",
      "Processing JSON files:  54%|█████▎    | 1826/3411 [00:43<00:30, 52.21file/s]\u001b[A\n",
      "Processing JSON files:  54%|█████▎    | 1833/3411 [00:43<00:28, 56.26file/s]\u001b[A\n",
      "Processing JSON files:  54%|█████▍    | 1840/3411 [00:43<00:26, 58.97file/s]\u001b[A\n",
      "Processing JSON files:  54%|█████▍    | 1847/3411 [00:43<00:25, 60.55file/s]\u001b[A\n",
      "Processing JSON files:  54%|█████▍    | 1854/3411 [00:43<00:26, 58.53file/s]\u001b[A\n",
      "Processing JSON files:  55%|█████▍    | 1860/3411 [00:43<00:28, 55.16file/s]\u001b[A\n",
      "Processing JSON files:  55%|█████▍    | 1868/3411 [00:43<00:26, 58.81file/s]\u001b[A\n",
      "Processing JSON files:  55%|█████▍    | 1875/3411 [00:43<00:25, 59.17file/s]\u001b[A\n",
      "Processing JSON files:  55%|█████▌    | 1882/3411 [00:44<00:25, 59.81file/s]\u001b[A\n",
      "Processing JSON files:  55%|█████▌    | 1888/3411 [00:44<00:26, 57.42file/s]\u001b[A\n",
      "Processing JSON files:  56%|█████▌    | 1894/3411 [00:44<00:27, 55.98file/s]\u001b[A\n",
      "Processing JSON files:  56%|█████▌    | 1902/3411 [00:44<00:24, 61.41file/s]\u001b[A\n",
      "Processing JSON files:  56%|█████▌    | 1909/3411 [00:44<00:24, 61.26file/s]\u001b[A\n",
      "Processing JSON files:  56%|█████▌    | 1916/3411 [00:44<00:24, 61.53file/s]\u001b[A\n",
      "Processing JSON files:  56%|█████▋    | 1923/3411 [00:44<00:27, 53.77file/s]\u001b[A\n",
      "Processing JSON files:  57%|█████▋    | 1929/3411 [00:44<00:27, 54.54file/s]\u001b[A\n",
      "Processing JSON files:  57%|█████▋    | 1936/3411 [00:44<00:25, 58.54file/s]\u001b[A\n",
      "Processing JSON files:  57%|█████▋    | 1943/3411 [00:45<00:25, 56.60file/s]\u001b[A\n",
      "Processing JSON files:  57%|█████▋    | 1949/3411 [00:45<00:26, 55.79file/s]\u001b[A\n",
      "Processing JSON files:  57%|█████▋    | 1955/3411 [00:45<00:25, 56.50file/s]\u001b[A\n",
      "Processing JSON files:  58%|█████▊    | 1963/3411 [00:45<00:23, 61.43file/s]\u001b[A\n",
      "Processing JSON files:  58%|█████▊    | 1971/3411 [00:45<00:22, 64.26file/s]\u001b[A\n",
      "Processing JSON files:  58%|█████▊    | 1978/3411 [00:45<00:22, 64.62file/s]\u001b[A\n",
      "Processing JSON files:  58%|█████▊    | 1985/3411 [00:45<00:23, 60.76file/s]\u001b[A\n",
      "Processing JSON files:  58%|█████▊    | 1992/3411 [00:45<00:23, 60.30file/s]\u001b[A\n",
      "Processing JSON files:  59%|█████▊    | 1999/3411 [00:46<00:22, 61.58file/s]\u001b[A\n",
      "Processing JSON files:  59%|█████▉    | 2006/3411 [00:46<00:22, 61.23file/s]\u001b[A\n",
      "Processing JSON files:  59%|█████▉    | 2013/3411 [00:46<00:22, 62.59file/s]\u001b[A\n",
      "Processing JSON files:  59%|█████▉    | 2020/3411 [00:46<00:22, 63.12file/s]\u001b[A\n",
      "Processing JSON files:  59%|█████▉    | 2027/3411 [00:46<00:23, 59.68file/s]\u001b[A\n",
      "Processing JSON files:  60%|█████▉    | 2034/3411 [00:46<00:22, 61.75file/s]\u001b[A\n",
      "Processing JSON files:  60%|█████▉    | 2042/3411 [00:46<00:20, 65.63file/s]\u001b[A\n",
      "Processing JSON files:  60%|██████    | 2049/3411 [00:46<00:21, 64.59file/s]\u001b[A\n",
      "Processing JSON files:  60%|██████    | 2056/3411 [00:46<00:20, 65.42file/s]\u001b[A\n",
      "Processing JSON files:  60%|██████    | 2063/3411 [00:47<00:22, 59.47file/s]\u001b[A\n",
      "Processing JSON files:  61%|██████    | 2070/3411 [00:47<00:21, 61.01file/s]\u001b[A\n",
      "Processing JSON files:  61%|██████    | 2077/3411 [00:47<00:22, 60.35file/s]\u001b[A\n",
      "Processing JSON files:  61%|██████    | 2084/3411 [00:47<00:23, 57.22file/s]\u001b[A\n",
      "Processing JSON files:  61%|██████▏   | 2090/3411 [00:47<00:23, 57.26file/s]\u001b[A\n",
      "Processing JSON files:  61%|██████▏   | 2097/3411 [00:47<00:22, 58.67file/s]\u001b[A\n",
      "Processing JSON files:  62%|██████▏   | 2104/3411 [00:47<00:21, 60.27file/s]\u001b[A\n",
      "Processing JSON files:  62%|██████▏   | 2111/3411 [00:47<00:21, 60.34file/s]\u001b[A\n",
      "Processing JSON files:  62%|██████▏   | 2118/3411 [00:48<00:23, 54.61file/s]\u001b[A\n",
      "Processing JSON files:  62%|██████▏   | 2124/3411 [00:48<00:25, 51.40file/s]\u001b[A\n",
      "Processing JSON files:  62%|██████▏   | 2130/3411 [00:48<00:24, 53.19file/s]\u001b[A\n",
      "Processing JSON files:  63%|██████▎   | 2136/3411 [00:48<00:23, 54.73file/s]\u001b[A\n",
      "Processing JSON files:  63%|██████▎   | 2142/3411 [00:48<00:23, 53.17file/s]\u001b[A\n",
      "Processing JSON files:  63%|██████▎   | 2148/3411 [00:48<00:23, 54.46file/s]\u001b[A\n",
      "Processing JSON files:  63%|██████▎   | 2154/3411 [00:48<00:24, 51.41file/s]\u001b[A\n",
      "Processing JSON files:  63%|██████▎   | 2161/3411 [00:48<00:22, 55.60file/s]\u001b[A\n",
      "Processing JSON files:  64%|██████▎   | 2169/3411 [00:48<00:20, 61.44file/s]\u001b[A\n",
      "Processing JSON files:  64%|██████▍   | 2176/3411 [00:49<00:21, 57.58file/s]\u001b[A\n",
      "Processing JSON files:  64%|██████▍   | 2182/3411 [00:49<00:24, 50.67file/s]\u001b[A\n",
      "Processing JSON files:  64%|██████▍   | 2188/3411 [00:49<00:25, 48.44file/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files:  64%|██████▍   | 2195/3411 [00:49<00:22, 53.50file/s]\u001b[A\n",
      "Processing JSON files:  65%|██████▍   | 2202/3411 [00:49<00:21, 55.64file/s]\u001b[A\n",
      "Processing JSON files:  65%|██████▍   | 2208/3411 [00:49<00:22, 54.21file/s]\u001b[A\n",
      "Processing JSON files:  65%|██████▍   | 2214/3411 [00:49<00:22, 52.79file/s]\u001b[A\n",
      "Processing JSON files:  65%|██████▌   | 2221/3411 [00:49<00:20, 57.01file/s]\u001b[A\n",
      "Processing JSON files:  65%|██████▌   | 2228/3411 [00:50<00:19, 60.34file/s]\u001b[A\n",
      "Processing JSON files:  66%|██████▌   | 2235/3411 [00:50<00:19, 58.98file/s]\u001b[A\n",
      "Processing JSON files:  66%|██████▌   | 2241/3411 [00:50<00:20, 57.37file/s]\u001b[A\n",
      "Processing JSON files:  66%|██████▌   | 2247/3411 [00:50<00:22, 52.58file/s]\u001b[A\n",
      "Processing JSON files:  66%|██████▌   | 2253/3411 [00:50<00:22, 50.70file/s]\u001b[A\n",
      "Processing JSON files:  66%|██████▌   | 2259/3411 [00:50<00:23, 49.10file/s]\u001b[A\n",
      "Processing JSON files:  66%|██████▋   | 2266/3411 [00:50<00:21, 52.68file/s]\u001b[A\n",
      "Processing JSON files:  67%|██████▋   | 2274/3411 [00:50<00:19, 58.12file/s]\u001b[A\n",
      "Processing JSON files:  67%|██████▋   | 2280/3411 [00:50<00:20, 54.65file/s]\u001b[A\n",
      "Processing JSON files:  67%|██████▋   | 2287/3411 [00:51<00:19, 56.98file/s]\u001b[A\n",
      "Processing JSON files:  67%|██████▋   | 2296/3411 [00:51<00:17, 63.96file/s]\u001b[A\n",
      "Processing JSON files:  68%|██████▊   | 2303/3411 [00:51<00:17, 65.13file/s]\u001b[A\n",
      "Processing JSON files:  68%|██████▊   | 2310/3411 [00:51<00:17, 61.83file/s]\u001b[A\n",
      "Processing JSON files:  68%|██████▊   | 2317/3411 [00:51<00:17, 61.42file/s]\u001b[A\n",
      "Processing JSON files:  68%|██████▊   | 2324/3411 [00:51<00:17, 61.17file/s]\u001b[A\n",
      "Processing JSON files:  68%|██████▊   | 2331/3411 [00:51<00:18, 57.81file/s]\u001b[A\n",
      "Processing JSON files:  69%|██████▊   | 2337/3411 [00:51<00:18, 58.26file/s]\u001b[A\n",
      "Processing JSON files:  69%|██████▊   | 2343/3411 [00:52<00:19, 55.29file/s]\u001b[A\n",
      "Processing JSON files:  69%|██████▉   | 2349/3411 [00:52<00:19, 53.89file/s]\u001b[A\n",
      "Processing JSON files:  69%|██████▉   | 2355/3411 [00:52<00:20, 52.18file/s]\u001b[A\n",
      "Processing JSON files:  69%|██████▉   | 2361/3411 [00:52<00:23, 45.50file/s]\u001b[A\n",
      "Processing JSON files:  69%|██████▉   | 2366/3411 [00:52<00:24, 42.90file/s]\u001b[A\n",
      "Processing JSON files:  70%|██████▉   | 2372/3411 [00:52<00:23, 44.90file/s]\u001b[A\n",
      "Processing JSON files:  70%|██████▉   | 2377/3411 [00:52<00:23, 44.91file/s]\u001b[A\n",
      "Processing JSON files:  70%|██████▉   | 2382/3411 [00:52<00:23, 43.90file/s]\u001b[A\n",
      "Processing JSON files:  70%|██████▉   | 2387/3411 [00:53<00:24, 41.33file/s]\u001b[A\n",
      "Processing JSON files:  70%|███████   | 2392/3411 [00:53<00:26, 38.22file/s]\u001b[A\n",
      "Processing JSON files:  70%|███████   | 2397/3411 [00:53<00:25, 39.60file/s]\u001b[A\n",
      "Processing JSON files:  70%|███████   | 2402/3411 [00:53<00:25, 40.21file/s]\u001b[A\n",
      "Processing JSON files:  71%|███████   | 2407/3411 [00:53<00:24, 40.64file/s]\u001b[A\n",
      "Processing JSON files:  71%|███████   | 2412/3411 [00:53<00:24, 40.13file/s]\u001b[A\n",
      "Processing JSON files:  71%|███████   | 2417/3411 [00:53<00:26, 36.89file/s]\u001b[A\n",
      "Processing JSON files:  71%|███████   | 2423/3411 [00:53<00:23, 41.25file/s]\u001b[A\n",
      "Processing JSON files:  71%|███████   | 2428/3411 [00:54<00:23, 41.47file/s]\u001b[A\n",
      "Processing JSON files:  71%|███████▏  | 2434/3411 [00:54<00:21, 44.47file/s]\u001b[A\n",
      "Processing JSON files:  72%|███████▏  | 2440/3411 [00:54<00:20, 47.96file/s]\u001b[A\n",
      "Processing JSON files:  72%|███████▏  | 2447/3411 [00:54<00:18, 52.16file/s]\u001b[A\n",
      "Processing JSON files:  72%|███████▏  | 2453/3411 [00:54<00:18, 52.49file/s]\u001b[A\n",
      "Processing JSON files:  72%|███████▏  | 2460/3411 [00:54<00:17, 55.07file/s]\u001b[A\n",
      "Processing JSON files:  72%|███████▏  | 2466/3411 [00:54<00:16, 56.01file/s]\u001b[A\n",
      "Processing JSON files:  72%|███████▏  | 2472/3411 [00:54<00:16, 55.47file/s]\u001b[A\n",
      "Processing JSON files:  73%|███████▎  | 2478/3411 [00:54<00:16, 55.35file/s]\u001b[A\n",
      "Processing JSON files:  73%|███████▎  | 2484/3411 [00:55<00:16, 54.71file/s]\u001b[A\n",
      "Processing JSON files:  73%|███████▎  | 2491/3411 [00:55<00:16, 56.63file/s]\u001b[A\n",
      "Processing JSON files:  73%|███████▎  | 2499/3411 [00:55<00:14, 61.70file/s]\u001b[A\n",
      "Processing JSON files:  73%|███████▎  | 2506/3411 [00:55<00:15, 59.63file/s]\u001b[A\n",
      "Processing JSON files:  74%|███████▎  | 2513/3411 [00:55<00:14, 60.66file/s]\u001b[A\n",
      "Processing JSON files:  74%|███████▍  | 2520/3411 [00:55<00:15, 57.50file/s]\u001b[A\n",
      "Processing JSON files:  74%|███████▍  | 2526/3411 [00:55<00:16, 54.84file/s]\u001b[A\n",
      "Processing JSON files:  74%|███████▍  | 2532/3411 [00:55<00:17, 49.21file/s]\u001b[A\n",
      "Processing JSON files:  74%|███████▍  | 2538/3411 [00:56<00:18, 46.21file/s]\u001b[A\n",
      "Processing JSON files:  75%|███████▍  | 2544/3411 [00:56<00:18, 47.60file/s]\u001b[A\n",
      "Processing JSON files:  75%|███████▍  | 2550/3411 [00:56<00:17, 49.78file/s]\u001b[A\n",
      "Processing JSON files:  75%|███████▍  | 2556/3411 [00:56<00:16, 50.92file/s]\u001b[A\n",
      "Processing JSON files:  75%|███████▌  | 2562/3411 [00:56<00:16, 51.19file/s]\u001b[A\n",
      "Processing JSON files:  75%|███████▌  | 2568/3411 [00:56<00:15, 53.42file/s]\u001b[A\n",
      "Processing JSON files:  75%|███████▌  | 2575/3411 [00:56<00:14, 57.87file/s]\u001b[A\n",
      "Processing JSON files:  76%|███████▌  | 2583/3411 [00:56<00:13, 62.56file/s]\u001b[A\n",
      "Processing JSON files:  76%|███████▌  | 2590/3411 [00:56<00:13, 61.91file/s]\u001b[A\n",
      "Processing JSON files:  76%|███████▌  | 2597/3411 [00:57<00:14, 56.58file/s]\u001b[A\n",
      "Processing JSON files:  76%|███████▋  | 2603/3411 [00:57<00:14, 56.77file/s]\u001b[A\n",
      "Processing JSON files:  77%|███████▋  | 2610/3411 [00:57<00:13, 58.53file/s]\u001b[A\n",
      "Processing JSON files:  77%|███████▋  | 2616/3411 [00:57<00:13, 58.54file/s]\u001b[A\n",
      "Processing JSON files:  77%|███████▋  | 2622/3411 [00:57<00:14, 54.27file/s]\u001b[A\n",
      "Processing JSON files:  77%|███████▋  | 2630/3411 [00:57<00:13, 60.03file/s]\u001b[A\n",
      "Processing JSON files:  77%|███████▋  | 2639/3411 [00:57<00:11, 66.43file/s]\u001b[A\n",
      "Processing JSON files:  78%|███████▊  | 2646/3411 [00:57<00:12, 61.99file/s]\u001b[A\n",
      "Processing JSON files:  78%|███████▊  | 2653/3411 [00:58<00:11, 64.08file/s]\u001b[A\n",
      "Processing JSON files:  78%|███████▊  | 2660/3411 [00:58<00:11, 62.86file/s]\u001b[A\n",
      "Processing JSON files:  78%|███████▊  | 2667/3411 [00:58<00:12, 61.67file/s]\u001b[A\n",
      "Processing JSON files:  78%|███████▊  | 2674/3411 [00:58<00:12, 56.86file/s]\u001b[A\n",
      "Processing JSON files:  79%|███████▊  | 2680/3411 [00:58<00:13, 55.53file/s]\u001b[A\n",
      "Processing JSON files:  79%|███████▊  | 2686/3411 [00:58<00:12, 56.34file/s]\u001b[A\n",
      "Processing JSON files:  79%|███████▉  | 2692/3411 [00:58<00:13, 55.30file/s]\u001b[A\n",
      "Processing JSON files:  79%|███████▉  | 2698/3411 [00:58<00:13, 54.70file/s]\u001b[A\n",
      "Processing JSON files:  79%|███████▉  | 2706/3411 [00:58<00:11, 59.45file/s]\u001b[A\n",
      "Processing JSON files:  80%|███████▉  | 2712/3411 [00:59<00:12, 55.33file/s]\u001b[A\n",
      "Processing JSON files:  80%|███████▉  | 2718/3411 [00:59<00:13, 52.40file/s]\u001b[A\n",
      "Processing JSON files:  80%|███████▉  | 2724/3411 [00:59<00:13, 50.18file/s]\u001b[A\n",
      "Processing JSON files:  80%|████████  | 2730/3411 [00:59<00:13, 49.30file/s]\u001b[A\n",
      "Processing JSON files:  80%|████████  | 2735/3411 [00:59<00:13, 49.33file/s]\u001b[A\n",
      "Processing JSON files:  80%|████████  | 2740/3411 [00:59<00:14, 47.16file/s]\u001b[A\n",
      "Processing JSON files:  80%|████████  | 2745/3411 [00:59<00:15, 44.03file/s]\u001b[A\n",
      "Processing JSON files:  81%|████████  | 2751/3411 [00:59<00:13, 47.98file/s]\u001b[A\n",
      "Processing JSON files:  81%|████████  | 2756/3411 [01:00<00:14, 45.20file/s]\u001b[A\n",
      "Processing JSON files:  81%|████████  | 2761/3411 [01:00<00:15, 43.07file/s]\u001b[A\n",
      "Processing JSON files:  81%|████████  | 2768/3411 [01:00<00:13, 48.64file/s]\u001b[A\n",
      "Processing JSON files:  81%|████████▏ | 2773/3411 [01:00<00:13, 48.05file/s]\u001b[A\n",
      "Processing JSON files:  81%|████████▏ | 2779/3411 [01:00<00:12, 48.96file/s]\u001b[A\n",
      "Processing JSON files:  82%|████████▏ | 2784/3411 [01:00<00:15, 40.15file/s]\u001b[A\n",
      "Processing JSON files:  82%|████████▏ | 2789/3411 [01:00<00:15, 41.09file/s]\u001b[A\n",
      "Processing JSON files:  82%|████████▏ | 2797/3411 [01:00<00:12, 48.61file/s]\u001b[A\n",
      "Processing JSON files:  82%|████████▏ | 2803/3411 [01:01<00:12, 47.35file/s]\u001b[A\n",
      "Processing JSON files:  82%|████████▏ | 2808/3411 [01:01<00:12, 47.80file/s]\u001b[A\n",
      "Processing JSON files:  82%|████████▏ | 2813/3411 [01:01<00:12, 47.64file/s]\u001b[A\n",
      "Processing JSON files:  83%|████████▎ | 2819/3411 [01:01<00:12, 48.48file/s]\u001b[A\n",
      "Processing JSON files:  83%|████████▎ | 2824/3411 [01:01<00:12, 46.42file/s]\u001b[A\n",
      "Processing JSON files:  83%|████████▎ | 2830/3411 [01:01<00:12, 48.14file/s]\u001b[A\n",
      "Processing JSON files:  83%|████████▎ | 2835/3411 [01:01<00:14, 40.78file/s]\u001b[A\n",
      "Processing JSON files:  83%|████████▎ | 2840/3411 [01:01<00:13, 40.96file/s]\u001b[A\n",
      "Processing JSON files:  83%|████████▎ | 2846/3411 [01:02<00:13, 42.61file/s]\u001b[A\n",
      "Processing JSON files:  84%|████████▎ | 2851/3411 [01:02<00:12, 44.29file/s]\u001b[A\n",
      "Processing JSON files:  84%|████████▎ | 2856/3411 [01:02<00:12, 45.59file/s]\u001b[A\n",
      "Processing JSON files:  84%|████████▍ | 2862/3411 [01:02<00:11, 45.94file/s]\u001b[A\n",
      "Processing JSON files:  84%|████████▍ | 2867/3411 [01:02<00:11, 46.18file/s]\u001b[A\n",
      "Processing JSON files:  84%|████████▍ | 2873/3411 [01:02<00:10, 49.48file/s]\u001b[A\n",
      "Processing JSON files:  84%|████████▍ | 2879/3411 [01:02<00:10, 51.46file/s]\u001b[A\n",
      "Processing JSON files:  85%|████████▍ | 2885/3411 [01:02<00:10, 50.83file/s]\u001b[A\n",
      "Processing JSON files:  85%|████████▍ | 2891/3411 [01:02<00:09, 52.94file/s]\u001b[A\n",
      "Processing JSON files:  85%|████████▍ | 2897/3411 [01:03<00:10, 50.64file/s]\u001b[A\n",
      "Processing JSON files:  85%|████████▌ | 2903/3411 [01:03<00:10, 48.89file/s]\u001b[A\n",
      "Processing JSON files:  85%|████████▌ | 2908/3411 [01:03<00:10, 47.88file/s]\u001b[A\n",
      "Processing JSON files:  85%|████████▌ | 2915/3411 [01:03<00:09, 51.83file/s]\u001b[A\n",
      "Processing JSON files:  86%|████████▌ | 2921/3411 [01:03<00:09, 52.49file/s]\u001b[A\n",
      "Processing JSON files:  86%|████████▌ | 2928/3411 [01:03<00:08, 56.09file/s]\u001b[A\n",
      "Processing JSON files:  86%|████████▌ | 2934/3411 [01:03<00:08, 54.15file/s]\u001b[A\n",
      "Processing JSON files:  86%|████████▌ | 2940/3411 [01:03<00:08, 52.43file/s]\u001b[A\n",
      "Processing JSON files:  86%|████████▋ | 2946/3411 [01:04<00:09, 47.28file/s]\u001b[A\n",
      "Processing JSON files:  87%|████████▋ | 2953/3411 [01:04<00:08, 51.55file/s]\u001b[A\n",
      "Processing JSON files:  87%|████████▋ | 2959/3411 [01:04<00:09, 49.60file/s]\u001b[A\n",
      "Processing JSON files:  87%|████████▋ | 2966/3411 [01:04<00:08, 52.27file/s]\u001b[A\n",
      "Processing JSON files:  87%|████████▋ | 2972/3411 [01:04<00:08, 50.61file/s]\u001b[A\n",
      "Processing JSON files:  87%|████████▋ | 2978/3411 [01:04<00:08, 49.92file/s]\u001b[A\n",
      "Processing JSON files:  87%|████████▋ | 2984/3411 [01:04<00:08, 49.94file/s]\u001b[A\n",
      "Processing JSON files:  88%|████████▊ | 2990/3411 [01:04<00:08, 51.73file/s]\u001b[A\n",
      "Processing JSON files:  88%|████████▊ | 2996/3411 [01:05<00:08, 48.72file/s]\u001b[A\n",
      "Processing JSON files:  88%|████████▊ | 3002/3411 [01:05<00:08, 50.86file/s]\u001b[A\n",
      "Processing JSON files:  88%|████████▊ | 3008/3411 [01:05<00:08, 46.43file/s]\u001b[A\n",
      "Processing JSON files:  88%|████████▊ | 3013/3411 [01:05<00:08, 47.23file/s]\u001b[A\n",
      "Processing JSON files:  89%|████████▊ | 3019/3411 [01:05<00:07, 50.22file/s]\u001b[A\n",
      "Processing JSON files:  89%|████████▊ | 3026/3411 [01:05<00:07, 53.88file/s]\u001b[A\n",
      "Processing JSON files:  89%|████████▉ | 3033/3411 [01:05<00:06, 56.21file/s]\u001b[A\n",
      "Processing JSON files:  89%|████████▉ | 3040/3411 [01:05<00:06, 59.94file/s]\u001b[A\n",
      "Processing JSON files:  89%|████████▉ | 3047/3411 [01:05<00:06, 58.69file/s]\u001b[A\n",
      "Processing JSON files:  90%|████████▉ | 3053/3411 [01:06<00:06, 58.64file/s]\u001b[A\n",
      "Processing JSON files:  90%|████████▉ | 3060/3411 [01:06<00:05, 60.17file/s]\u001b[A\n",
      "Processing JSON files:  90%|████████▉ | 3067/3411 [01:06<00:05, 62.31file/s]\u001b[A\n",
      "Processing JSON files:  90%|█████████ | 3074/3411 [01:06<00:05, 58.33file/s]\u001b[A\n",
      "Processing JSON files:  90%|█████████ | 3081/3411 [01:06<00:05, 59.86file/s]\u001b[A\n",
      "Processing JSON files:  91%|█████████ | 3088/3411 [01:06<00:05, 58.58file/s]\u001b[A\n",
      "Processing JSON files:  91%|█████████ | 3094/3411 [01:06<00:05, 57.86file/s]\u001b[A\n",
      "Processing JSON files:  91%|█████████ | 3101/3411 [01:06<00:05, 58.18file/s]\u001b[A\n",
      "Processing JSON files:  91%|█████████ | 3107/3411 [01:07<00:05, 51.44file/s]\u001b[A\n",
      "Processing JSON files:  91%|█████████▏| 3113/3411 [01:07<00:06, 46.49file/s]\u001b[A\n",
      "Processing JSON files:  91%|█████████▏| 3119/3411 [01:07<00:05, 48.98file/s]\u001b[A\n",
      "Processing JSON files:  92%|█████████▏| 3125/3411 [01:07<00:05, 48.76file/s]\u001b[A\n",
      "Processing JSON files:  92%|█████████▏| 3131/3411 [01:07<00:05, 49.39file/s]\u001b[A\n",
      "Processing JSON files:  92%|█████████▏| 3137/3411 [01:07<00:05, 45.91file/s]\u001b[A\n",
      "Processing JSON files:  92%|█████████▏| 3142/3411 [01:07<00:06, 42.13file/s]\u001b[A\n",
      "Processing JSON files:  92%|█████████▏| 3147/3411 [01:07<00:06, 39.83file/s]\u001b[A\n",
      "Processing JSON files:  92%|█████████▏| 3154/3411 [01:08<00:05, 45.73file/s]\u001b[A\n",
      "Processing JSON files:  93%|█████████▎| 3160/3411 [01:08<00:05, 49.09file/s]\u001b[A\n",
      "Processing JSON files:  93%|█████████▎| 3167/3411 [01:08<00:04, 52.52file/s]\u001b[A\n",
      "Processing JSON files:  93%|█████████▎| 3173/3411 [01:08<00:04, 54.25file/s]\u001b[A\n",
      "Processing JSON files:  93%|█████████▎| 3179/3411 [01:08<00:04, 53.71file/s]\u001b[A\n",
      "Processing JSON files:  93%|█████████▎| 3185/3411 [01:08<00:04, 55.09file/s]\u001b[A\n",
      "Processing JSON files:  94%|█████████▎| 3191/3411 [01:08<00:04, 51.79file/s]\u001b[A\n",
      "Processing JSON files:  94%|█████████▍| 3198/3411 [01:08<00:03, 55.39file/s]\u001b[A\n",
      "Processing JSON files:  94%|█████████▍| 3204/3411 [01:08<00:03, 55.72file/s]\u001b[A\n",
      "Processing JSON files:  94%|█████████▍| 3210/3411 [01:09<00:03, 56.87file/s]\u001b[A\n",
      "Processing JSON files:  94%|█████████▍| 3216/3411 [01:09<00:03, 54.91file/s]\u001b[A\n",
      "Processing JSON files:  94%|█████████▍| 3222/3411 [01:09<00:03, 49.30file/s]\u001b[A\n",
      "Processing JSON files:  95%|█████████▍| 3228/3411 [01:09<00:03, 51.09file/s]\u001b[A\n",
      "Processing JSON files:  95%|█████████▍| 3234/3411 [01:09<00:03, 52.86file/s]\u001b[A\n",
      "Processing JSON files:  95%|█████████▍| 3240/3411 [01:09<00:03, 49.38file/s]\u001b[A\n",
      "Processing JSON files:  95%|█████████▌| 3246/3411 [01:09<00:03, 50.31file/s]\u001b[A\n",
      "Processing JSON files:  95%|█████████▌| 3252/3411 [01:09<00:03, 52.42file/s]\u001b[A\n",
      "Processing JSON files:  96%|█████████▌| 3258/3411 [01:10<00:03, 49.88file/s]\u001b[A\n",
      "Processing JSON files:  96%|█████████▌| 3265/3411 [01:10<00:02, 53.90file/s]\u001b[A\n",
      "Processing JSON files:  96%|█████████▌| 3271/3411 [01:10<00:02, 53.97file/s]\u001b[A\n",
      "Processing JSON files:  96%|█████████▌| 3277/3411 [01:10<00:02, 50.65file/s]\u001b[A\n",
      "Processing JSON files:  96%|█████████▌| 3283/3411 [01:10<00:02, 51.99file/s]\u001b[A\n",
      "Processing JSON files:  96%|█████████▋| 3289/3411 [01:10<00:02, 51.00file/s]\u001b[A\n",
      "Processing JSON files:  97%|█████████▋| 3295/3411 [01:10<00:02, 43.28file/s]\u001b[A\n",
      "Processing JSON files:  97%|█████████▋| 3300/3411 [01:10<00:02, 43.82file/s]\u001b[A\n",
      "Processing JSON files:  97%|█████████▋| 3306/3411 [01:11<00:02, 46.56file/s]\u001b[A\n",
      "Processing JSON files:  97%|█████████▋| 3314/3411 [01:11<00:01, 53.38file/s]\u001b[A\n",
      "Processing JSON files:  97%|█████████▋| 3321/3411 [01:11<00:01, 56.38file/s]\u001b[A\n",
      "Processing JSON files:  98%|█████████▊| 3327/3411 [01:11<00:01, 55.16file/s]\u001b[A\n",
      "Processing JSON files:  98%|█████████▊| 3333/3411 [01:11<00:01, 54.99file/s]\u001b[A\n",
      "Processing JSON files:  98%|█████████▊| 3340/3411 [01:11<00:01, 57.81file/s]\u001b[A\n",
      "Processing JSON files:  98%|█████████▊| 3346/3411 [01:11<00:01, 56.94file/s]\u001b[A\n",
      "Processing JSON files:  98%|█████████▊| 3352/3411 [01:11<00:01, 56.54file/s]\u001b[A\n",
      "Processing JSON files:  98%|█████████▊| 3358/3411 [01:11<00:00, 56.75file/s]\u001b[A\n",
      "Processing JSON files:  99%|█████████▊| 3364/3411 [01:12<00:00, 53.28file/s]\u001b[A\n",
      "Processing JSON files:  99%|█████████▉| 3370/3411 [01:12<00:00, 47.35file/s]\u001b[A\n",
      "Processing JSON files:  99%|█████████▉| 3376/3411 [01:12<00:00, 48.72file/s]\u001b[A\n",
      "Processing JSON files:  99%|█████████▉| 3382/3411 [01:12<00:00, 51.06file/s]\u001b[A\n",
      "Processing JSON files:  99%|█████████▉| 3388/3411 [01:12<00:00, 48.96file/s]\u001b[A\n",
      "Processing JSON files:  99%|█████████▉| 3393/3411 [01:12<00:00, 48.42file/s]\u001b[A\n",
      "Processing JSON files: 100%|█████████▉| 3399/3411 [01:12<00:00, 49.91file/s]\u001b[A\n",
      "Processing JSON files: 100%|█████████▉| 3405/3411 [01:12<00:00, 49.29file/s]\u001b[A\n",
      "Processing JSON files: 100%|█████████▉| 3410/3411 [01:13<00:00, 47.86file/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing JSON files: 100%|██████████| 3411/3411 [01:31<00:00, 47.86file/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Choose the right file path\n",
    "folder_path = r\"C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_2\"\n",
    "\n",
    "# Get the list of JSON files in the specified directory\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.json')]\n",
    "\n",
    "# Calculate the total number of JSON files\n",
    "total_files = len(file_list)\n",
    "\n",
    "# Initialize an empty list to store individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Create a tqdm instance to track the progress\n",
    "progress_bar = tqdm(total=total_files, desc=\"Processing JSON files\", unit=\"file\")\n",
    "\n",
    "# Read each JSON file and append its DataFrame to the list\n",
    "for file in file_list:\n",
    "    df = pd.read_json(file)\n",
    "    dataframes.append(df)\n",
    "    \n",
    "    # Update the progress bar after each iteration\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Convert the time column to datetime format\n",
    "merged_df['time'] = pd.to_datetime(merged_df['time'], unit='s')\n",
    "\n",
    "# Change the format of the time column to dd-mm-yyyy\n",
    "merged_df['time'] = merged_df['time'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Sort the DataFrame by the \"time\" column using a custom key function\n",
    "df_sorted = merged_df.sort_values('time', key=lambda x: pd.to_datetime(x, format='%d-%m-%Y', errors='coerce'))\n",
    "\n",
    "# Give name to CSV file\n",
    "csv_file_path = os.path.join(folder_path, 'sorted_Nvidia_2.csv')\n",
    "\n",
    "# Save the sorted DataFrame to a CSV file\n",
    "df_sorted.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Display a message indicating that the process is completed\n",
    "print(\"CSV file has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c590573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_0\\sorted_Nvidia_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db5a180b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>524797770</td>\n",
       "      <td>$NVDA thank you for the 250 percent gainer on ...</td>\n",
       "      <td>26-04-2023</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>524868442</td>\n",
       "      <td>$NVDA just wait for META to mention AI and the...</td>\n",
       "      <td>26-04-2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>524870531</td>\n",
       "      <td>$NVDA prepare for a big rise!!</td>\n",
       "      <td>26-04-2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524870756</td>\n",
       "      <td>$BRSH 🚀\\n\\n$SPY \\n$TQQQ \\n$NVDA \\n$ATOM</td>\n",
       "      <td>26-04-2023</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>524870820</td>\n",
       "      <td>$NVDA going to 275 if meta holds!!</td>\n",
       "      <td>26-04-2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text        time  \\\n",
       "0  524797770  $NVDA thank you for the 250 percent gainer on ...  26-04-2023   \n",
       "1  524868442  $NVDA just wait for META to mention AI and the...  26-04-2023   \n",
       "2  524870531                     $NVDA prepare for a big rise!!  26-04-2023   \n",
       "3  524870756            $BRSH 🚀\\n\\n$SPY \\n$TQQQ \\n$NVDA \\n$ATOM  26-04-2023   \n",
       "4  524870820                 $NVDA going to 275 if meta holds!!  26-04-2023   \n",
       "\n",
       "  sentiment  \n",
       "0   Bullish  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3   Bullish  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b81b6664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90322</th>\n",
       "      <td>534970519</td>\n",
       "      <td>$MSFT GS gives verdict its top AI plays:\\n\\n- ...</td>\n",
       "      <td>07-07-2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90323</th>\n",
       "      <td>534970255</td>\n",
       "      <td>$NVDA enters bullish trend https://srnk.us/go/...</td>\n",
       "      <td>07-07-2023</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90324</th>\n",
       "      <td>534969666</td>\n",
       "      <td>$NVDA pre fix for death https://youtu.be/39cL3...</td>\n",
       "      <td>07-07-2023</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90325</th>\n",
       "      <td>534972972</td>\n",
       "      <td>$NVDA 406/397.56 /378 .. July 12-21+  \\nPossible?</td>\n",
       "      <td>07-07-2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90326</th>\n",
       "      <td>534983944</td>\n",
       "      <td>$TSLA Enron has never left Twittor, he is stil...</td>\n",
       "      <td>07-07-2023</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text  \\\n",
       "90322  534970519  $MSFT GS gives verdict its top AI plays:\\n\\n- ...   \n",
       "90323  534970255  $NVDA enters bullish trend https://srnk.us/go/...   \n",
       "90324  534969666  $NVDA pre fix for death https://youtu.be/39cL3...   \n",
       "90325  534972972  $NVDA 406/397.56 /378 .. July 12-21+  \\nPossible?   \n",
       "90326  534983944  $TSLA Enron has never left Twittor, he is stil...   \n",
       "\n",
       "             time sentiment  \n",
       "90322  07-07-2023       NaN  \n",
       "90323  07-07-2023   Bullish  \n",
       "90324  07-07-2023   Bearish  \n",
       "90325  07-07-2023       NaN  \n",
       "90326  07-07-2023   Bearish  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c47865db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90327"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b321cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c7e5ed6",
   "metadata": {},
   "source": [
    "## Concatenating .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e277de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 26/26 [00:25<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated data saved to C:\\Users\\sahma\\Desktop\\Thises\\TSLA\\finbert_TSLA_06_2020_to_06_2023.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to the folder containing the CSV files\n",
    "folder_path = r'C:\\Users\\sahma\\Desktop\\Thises\\TSLA'\n",
    "\n",
    "# List to store individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Get the list of CSV files in the folder\n",
    "csv_files = [filename for filename in os.listdir(folder_path) if filename.endswith('.csv')]\n",
    "\n",
    "# Create a progress bar\n",
    "progress_bar = tqdm(total=len(csv_files), desc='Processing Files')\n",
    "\n",
    "# Iterate through each CSV file\n",
    "for filename in csv_files:\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrame to a CSV file in the same folder\n",
    "concatenated_csv_path = os.path.join(folder_path, 'finbert_TSLA_06_2020_to_06_2023.csv')\n",
    "concatenated_df.to_csv(concatenated_csv_path, index=False)\n",
    "\n",
    "print(f'Concatenated data saved to {concatenated_csv_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cadf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\sahma\\Desktop\\Thises\\TSLA\\finbert_TSLA_06_2020_to_06_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6098c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>finbert_sentiment</th>\n",
       "      <th>finbert_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>488005848</td>\n",
       "      <td>$TSLA  BREAKING NEWS....TESLA HYPNOTIZES ENTIR...</td>\n",
       "      <td>30-09-2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>breaking newstesla hypnotizes entire watch aud...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488008153</td>\n",
       "      <td>$SOFI  can we all appreciated Michael Burry’s ...</td>\n",
       "      <td>30-09-2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>can we all appreciated michael burrys analogy ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.996284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>488008139</td>\n",
       "      <td>$TSLA 245 waiting for you 😁</td>\n",
       "      <td>30-09-2022</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>245 waiting for you</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.907729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488008122</td>\n",
       "      <td>$TSLA This company is years and years ahead of...</td>\n",
       "      <td>30-09-2022</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>this company is years and years ahead of other...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.994367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488008121</td>\n",
       "      <td>$TSLA the IQ&amp;#39;s in that room 😄</td>\n",
       "      <td>30-09-2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the iq39s in that room</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text        time  \\\n",
       "0  488005848  $TSLA  BREAKING NEWS....TESLA HYPNOTIZES ENTIR...  30-09-2022   \n",
       "1  488008153  $SOFI  can we all appreciated Michael Burry’s ...  30-09-2022   \n",
       "2  488008139                        $TSLA 245 waiting for you 😁  30-09-2022   \n",
       "3  488008122  $TSLA This company is years and years ahead of...  30-09-2022   \n",
       "4  488008121                  $TSLA the IQ&#39;s in that room 😄  30-09-2022   \n",
       "\n",
       "  sentiment                                     processed_text  \\\n",
       "0       NaN  breaking newstesla hypnotizes entire watch aud...   \n",
       "1       NaN  can we all appreciated michael burrys analogy ...   \n",
       "2   Bearish                                245 waiting for you   \n",
       "3   Bullish  this company is years and years ahead of other...   \n",
       "4       NaN                             the iq39s in that room   \n",
       "\n",
       "  finbert_sentiment  finbert_score  \n",
       "0           Neutral       0.999999  \n",
       "1           Neutral       0.996284  \n",
       "2           Neutral       0.907729  \n",
       "3           Neutral       0.994367  \n",
       "4           Neutral       0.999992  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0fed589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>finbert_sentiment</th>\n",
       "      <th>finbert_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2736653</th>\n",
       "      <td>268681144</td>\n",
       "      <td>$TSLA its so amusing when in a bull scalp its ...</td>\n",
       "      <td>31-12-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>its so amusing when in a bull scalp its so eas...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.888716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736654</th>\n",
       "      <td>268681239</td>\n",
       "      <td>$TSLA gamble on the EOD crash and buy back up,...</td>\n",
       "      <td>31-12-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gamble on the eod crash and buy back up like w...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.949054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736655</th>\n",
       "      <td>268681328</td>\n",
       "      <td>$TSLA now is the time for me, opening $500 put...</td>\n",
       "      <td>31-12-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>now is the time for me opening 500 puts for ma...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.997246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736656</th>\n",
       "      <td>268678110</td>\n",
       "      <td>$TSLA your friendly neighborhood bear gotta ea...</td>\n",
       "      <td>31-12-2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>your friendly neighborhood bear got to eat too...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.999284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736657</th>\n",
       "      <td>268859974</td>\n",
       "      <td>$NIO $XPEV $TSLA whose getting drunk at tonigh...</td>\n",
       "      <td>31-12-2020</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>whose getting drunk at tonight holla ev bi</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.999780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text  \\\n",
       "2736653  268681144  $TSLA its so amusing when in a bull scalp its ...   \n",
       "2736654  268681239  $TSLA gamble on the EOD crash and buy back up,...   \n",
       "2736655  268681328  $TSLA now is the time for me, opening $500 put...   \n",
       "2736656  268678110  $TSLA your friendly neighborhood bear gotta ea...   \n",
       "2736657  268859974  $NIO $XPEV $TSLA whose getting drunk at tonigh...   \n",
       "\n",
       "               time sentiment  \\\n",
       "2736653  31-12-2020       NaN   \n",
       "2736654  31-12-2020       NaN   \n",
       "2736655  31-12-2020       NaN   \n",
       "2736656  31-12-2020       NaN   \n",
       "2736657  31-12-2020   Bullish   \n",
       "\n",
       "                                            processed_text finbert_sentiment  \\\n",
       "2736653  its so amusing when in a bull scalp its so eas...           Neutral   \n",
       "2736654  gamble on the eod crash and buy back up like w...           Neutral   \n",
       "2736655  now is the time for me opening 500 puts for ma...           Neutral   \n",
       "2736656  your friendly neighborhood bear got to eat too...           Neutral   \n",
       "2736657         whose getting drunk at tonight holla ev bi           Neutral   \n",
       "\n",
       "         finbert_score  \n",
       "2736653       0.888716  \n",
       "2736654       0.949054  \n",
       "2736655       0.997246  \n",
       "2736656       0.999284  \n",
       "2736657       0.999780  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87da6ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum time: 2023-07-07\n"
     ]
    }
   ],
   "source": [
    "#Find the maximum value in the time column\n",
    "max_time = max(df['time'])\n",
    "print(\"Maximum time:\", max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd285a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3d7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dbfcdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the desired columns\n",
    "selected_columns = ['id', 'body', 'created_at', 'entities']\n",
    "df = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7384e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439881211</td>\n",
       "      <td>$NVDA I see a 20 $ move to the upside</td>\n",
       "      <td>2022-02-28T14:54:52Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439881067</td>\n",
       "      <td>$NVDA holding 💎📈</td>\n",
       "      <td>2022-02-28T14:54:30Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439880835</td>\n",
       "      <td>$NVDA  about to moon … again</td>\n",
       "      <td>2022-02-28T14:54:00Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439880275</td>\n",
       "      <td>$NVDA got some calls for a few weeks out and s...</td>\n",
       "      <td>2022-02-28T14:52:40Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439879846</td>\n",
       "      <td>$NVDA I’m buying this it looks like bottom</td>\n",
       "      <td>2022-02-28T14:51:39Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               body  \\\n",
       "0  439881211              $NVDA I see a 20 $ move to the upside   \n",
       "1  439881067                                   $NVDA holding 💎📈   \n",
       "2  439880835                       $NVDA  about to moon … again   \n",
       "3  439880275  $NVDA got some calls for a few weeks out and s...   \n",
       "4  439879846         $NVDA I’m buying this it looks like bottom   \n",
       "\n",
       "             created_at                             entities  \n",
       "0  2022-02-28T14:54:52Z  {'sentiment': {'basic': 'Bullish'}}  \n",
       "1  2022-02-28T14:54:30Z  {'sentiment': {'basic': 'Bullish'}}  \n",
       "2  2022-02-28T14:54:00Z  {'sentiment': {'basic': 'Bullish'}}  \n",
       "3  2022-02-28T14:52:40Z  {'sentiment': {'basic': 'Bullish'}}  \n",
       "4  2022-02-28T14:51:39Z  {'sentiment': {'basic': 'Bullish'}}  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0c7c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "column_mapping = {\n",
    "    'body': 'text',\n",
    "    'created_at': 'time',\n",
    "    'entities': 'sentiment'\n",
    "}\n",
    "df.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e23babf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439881211</td>\n",
       "      <td>$NVDA I see a 20 $ move to the upside</td>\n",
       "      <td>2022-02-28T14:54:52Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439881067</td>\n",
       "      <td>$NVDA holding 💎📈</td>\n",
       "      <td>2022-02-28T14:54:30Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439880835</td>\n",
       "      <td>$NVDA  about to moon … again</td>\n",
       "      <td>2022-02-28T14:54:00Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439880275</td>\n",
       "      <td>$NVDA got some calls for a few weeks out and s...</td>\n",
       "      <td>2022-02-28T14:52:40Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439879846</td>\n",
       "      <td>$NVDA I’m buying this it looks like bottom</td>\n",
       "      <td>2022-02-28T14:51:39Z</td>\n",
       "      <td>{'sentiment': {'basic': 'Bullish'}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  \\\n",
       "0  439881211              $NVDA I see a 20 $ move to the upside   \n",
       "1  439881067                                   $NVDA holding 💎📈   \n",
       "2  439880835                       $NVDA  about to moon … again   \n",
       "3  439880275  $NVDA got some calls for a few weeks out and s...   \n",
       "4  439879846         $NVDA I’m buying this it looks like bottom   \n",
       "\n",
       "                   time                            sentiment  \n",
       "0  2022-02-28T14:54:52Z  {'sentiment': {'basic': 'Bullish'}}  \n",
       "1  2022-02-28T14:54:30Z  {'sentiment': {'basic': 'Bullish'}}  \n",
       "2  2022-02-28T14:54:00Z  {'sentiment': {'basic': 'Bullish'}}  \n",
       "3  2022-02-28T14:52:40Z  {'sentiment': {'basic': 'Bullish'}}  \n",
       "4  2022-02-28T14:51:39Z  {'sentiment': {'basic': 'Bullish'}}  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a3bae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'time' column to datetime format\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Format 'time' column as year-month-day\n",
    "df['time'] = df['time'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c2a2874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439881211</td>\n",
       "      <td>$NVDA I see a 20 $ move to the upside</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439881067</td>\n",
       "      <td>$NVDA holding 💎📈</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439880835</td>\n",
       "      <td>$NVDA  about to moon … again</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439880275</td>\n",
       "      <td>$NVDA got some calls for a few weeks out and s...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439879846</td>\n",
       "      <td>$NVDA I’m buying this it looks like bottom</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>439879458</td>\n",
       "      <td>$NVDA 231</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>439879282</td>\n",
       "      <td>$NVDA 270 price target 1 second is 300</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>439877933</td>\n",
       "      <td>$NVDA a few more and it turns green and we bac...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>439877328</td>\n",
       "      <td>$NVDA give us a 20$ move up sir</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>439876825</td>\n",
       "      <td>$NVDA red To green Imo</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>439875981</td>\n",
       "      <td>$NVDA 270 on the books</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>439875603</td>\n",
       "      <td>$TSM Still showing incredible weakness in rela...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>439875452</td>\n",
       "      <td>$NVDA Wait for the spike today .... wait for i...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>439875064</td>\n",
       "      <td>$NVDA long calls and shares on da dip will hol...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>439874982</td>\n",
       "      <td>$NVDA sorry but we going down</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bearish\"}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text        time  \\\n",
       "0   439881211              $NVDA I see a 20 $ move to the upside  2022-02-28   \n",
       "1   439881067                                   $NVDA holding 💎📈  2022-02-28   \n",
       "2   439880835                       $NVDA  about to moon … again  2022-02-28   \n",
       "3   439880275  $NVDA got some calls for a few weeks out and s...  2022-02-28   \n",
       "4   439879846         $NVDA I’m buying this it looks like bottom  2022-02-28   \n",
       "5   439879458                                          $NVDA 231  2022-02-28   \n",
       "6   439879282             $NVDA 270 price target 1 second is 300  2022-02-28   \n",
       "7   439877933  $NVDA a few more and it turns green and we bac...  2022-02-28   \n",
       "8   439877328                    $NVDA give us a 20$ move up sir  2022-02-28   \n",
       "9   439876825                             $NVDA red To green Imo  2022-02-28   \n",
       "10  439875981                             $NVDA 270 on the books  2022-02-28   \n",
       "11  439875603  $TSM Still showing incredible weakness in rela...  2022-02-28   \n",
       "12  439875452  $NVDA Wait for the spike today .... wait for i...  2022-02-28   \n",
       "13  439875064  $NVDA long calls and shares on da dip will hol...  2022-02-28   \n",
       "14  439874982                      $NVDA sorry but we going down  2022-02-28   \n",
       "\n",
       "                              sentiment  \n",
       "0   {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "1   {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "2   {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "3   {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "4   {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "5                   {\"sentiment\": None}  \n",
       "6   {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "7   {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "8   {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "9   {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "10  {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "11                  {\"sentiment\": None}  \n",
       "12  {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "13  {\"sentiment\": {\"basic\": \"Bullish\"}}  \n",
       "14  {\"sentiment\": {\"basic\": \"Bearish\"}}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f0bdd8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Use regular expressions to extract sentiment values\n",
    "pattern = r'{\"basic\": \"(.*?)\"}'\n",
    "df['sentiment_1'] = df['sentiment'].apply(lambda x: re.search(pattern, x).group(1) if re.search(pattern, x) else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c664b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439881211</td>\n",
       "      <td>$NVDA I see a 20 $ move to the upside</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439881067</td>\n",
       "      <td>$NVDA holding 💎📈</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439880835</td>\n",
       "      <td>$NVDA  about to moon … again</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439880275</td>\n",
       "      <td>$NVDA got some calls for a few weeks out and s...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439879846</td>\n",
       "      <td>$NVDA I’m buying this it looks like bottom</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>439879458</td>\n",
       "      <td>$NVDA 231</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": None}</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>439879282</td>\n",
       "      <td>$NVDA 270 price target 1 second is 300</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>439877933</td>\n",
       "      <td>$NVDA a few more and it turns green and we bac...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>439877328</td>\n",
       "      <td>$NVDA give us a 20$ move up sir</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>439876825</td>\n",
       "      <td>$NVDA red To green Imo</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>439875981</td>\n",
       "      <td>$NVDA 270 on the books</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>439875603</td>\n",
       "      <td>$TSM Still showing incredible weakness in rela...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": None}</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>439875452</td>\n",
       "      <td>$NVDA Wait for the spike today .... wait for i...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>439875064</td>\n",
       "      <td>$NVDA long calls and shares on da dip will hol...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bullish\"}}</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>439874982</td>\n",
       "      <td>$NVDA sorry but we going down</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>{\"sentiment\": {\"basic\": \"Bearish\"}}</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text        time  \\\n",
       "0   439881211              $NVDA I see a 20 $ move to the upside  2022-02-28   \n",
       "1   439881067                                   $NVDA holding 💎📈  2022-02-28   \n",
       "2   439880835                       $NVDA  about to moon … again  2022-02-28   \n",
       "3   439880275  $NVDA got some calls for a few weeks out and s...  2022-02-28   \n",
       "4   439879846         $NVDA I’m buying this it looks like bottom  2022-02-28   \n",
       "5   439879458                                          $NVDA 231  2022-02-28   \n",
       "6   439879282             $NVDA 270 price target 1 second is 300  2022-02-28   \n",
       "7   439877933  $NVDA a few more and it turns green and we bac...  2022-02-28   \n",
       "8   439877328                    $NVDA give us a 20$ move up sir  2022-02-28   \n",
       "9   439876825                             $NVDA red To green Imo  2022-02-28   \n",
       "10  439875981                             $NVDA 270 on the books  2022-02-28   \n",
       "11  439875603  $TSM Still showing incredible weakness in rela...  2022-02-28   \n",
       "12  439875452  $NVDA Wait for the spike today .... wait for i...  2022-02-28   \n",
       "13  439875064  $NVDA long calls and shares on da dip will hol...  2022-02-28   \n",
       "14  439874982                      $NVDA sorry but we going down  2022-02-28   \n",
       "\n",
       "                              sentiment sentiment_1  \n",
       "0   {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "1   {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "2   {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "3   {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "4   {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "5                   {\"sentiment\": None}              \n",
       "6   {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "7   {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "8   {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "9   {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "10  {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "11                  {\"sentiment\": None}              \n",
       "12  {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "13  {\"sentiment\": {\"basic\": \"Bullish\"}}     Bullish  \n",
       "14  {\"sentiment\": {\"basic\": \"Bearish\"}}     Bearish  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f30eb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'sentiment' column\n",
    "df.drop(columns=['sentiment'], inplace=True)\n",
    "\n",
    "# Rename 'sentiment_1' column to 'sentiment'\n",
    "df.rename(columns={'sentiment_1': 'sentiment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57965e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439881211</td>\n",
       "      <td>$NVDA I see a 20 $ move to the upside</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439881067</td>\n",
       "      <td>$NVDA holding 💎📈</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439880835</td>\n",
       "      <td>$NVDA  about to moon … again</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439880275</td>\n",
       "      <td>$NVDA got some calls for a few weeks out and s...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439879846</td>\n",
       "      <td>$NVDA I’m buying this it looks like bottom</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>439879458</td>\n",
       "      <td>$NVDA 231</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>439879282</td>\n",
       "      <td>$NVDA 270 price target 1 second is 300</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>439877933</td>\n",
       "      <td>$NVDA a few more and it turns green and we bac...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>439877328</td>\n",
       "      <td>$NVDA give us a 20$ move up sir</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>439876825</td>\n",
       "      <td>$NVDA red To green Imo</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>439875981</td>\n",
       "      <td>$NVDA 270 on the books</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>439875603</td>\n",
       "      <td>$TSM Still showing incredible weakness in rela...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>439875452</td>\n",
       "      <td>$NVDA Wait for the spike today .... wait for i...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>439875064</td>\n",
       "      <td>$NVDA long calls and shares on da dip will hol...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>439874982</td>\n",
       "      <td>$NVDA sorry but we going down</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bearish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text        time  \\\n",
       "0   439881211              $NVDA I see a 20 $ move to the upside  2022-02-28   \n",
       "1   439881067                                   $NVDA holding 💎📈  2022-02-28   \n",
       "2   439880835                       $NVDA  about to moon … again  2022-02-28   \n",
       "3   439880275  $NVDA got some calls for a few weeks out and s...  2022-02-28   \n",
       "4   439879846         $NVDA I’m buying this it looks like bottom  2022-02-28   \n",
       "5   439879458                                          $NVDA 231  2022-02-28   \n",
       "6   439879282             $NVDA 270 price target 1 second is 300  2022-02-28   \n",
       "7   439877933  $NVDA a few more and it turns green and we bac...  2022-02-28   \n",
       "8   439877328                    $NVDA give us a 20$ move up sir  2022-02-28   \n",
       "9   439876825                             $NVDA red To green Imo  2022-02-28   \n",
       "10  439875981                             $NVDA 270 on the books  2022-02-28   \n",
       "11  439875603  $TSM Still showing incredible weakness in rela...  2022-02-28   \n",
       "12  439875452  $NVDA Wait for the spike today .... wait for i...  2022-02-28   \n",
       "13  439875064  $NVDA long calls and shares on da dip will hol...  2022-02-28   \n",
       "14  439874982                      $NVDA sorry but we going down  2022-02-28   \n",
       "\n",
       "   sentiment  \n",
       "0    Bullish  \n",
       "1    Bullish  \n",
       "2    Bullish  \n",
       "3    Bullish  \n",
       "4    Bullish  \n",
       "5             \n",
       "6    Bullish  \n",
       "7    Bullish  \n",
       "8    Bullish  \n",
       "9    Bullish  \n",
       "10   Bullish  \n",
       "11            \n",
       "12   Bullish  \n",
       "13   Bullish  \n",
       "14   Bearish  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e51e199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584176</th>\n",
       "      <td>12997231</td>\n",
       "      <td>Nvidia investing in â€˜once in a lifetime oppo...</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584177</th>\n",
       "      <td>12995655</td>\n",
       "      <td>$NVDA shorting here is like picking up dimes i...</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584178</th>\n",
       "      <td>12995587</td>\n",
       "      <td>As I said just over a week ago that $NVDA woul...</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584179</th>\n",
       "      <td>12995313</td>\n",
       "      <td>$NVDA quite a rebound today, i can hardly beli...</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584180</th>\n",
       "      <td>12994205</td>\n",
       "      <td>$NVDA shorts using a lot of ammo trying to kee...</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text  \\\n",
       "584176  12997231  Nvidia investing in â€˜once in a lifetime oppo...   \n",
       "584177  12995655  $NVDA shorting here is like picking up dimes i...   \n",
       "584178  12995587  As I said just over a week ago that $NVDA woul...   \n",
       "584179  12995313  $NVDA quite a rebound today, i can hardly beli...   \n",
       "584180  12994205  $NVDA shorts using a lot of ammo trying to kee...   \n",
       "\n",
       "              time sentiment  \n",
       "584176  2013-04-11            \n",
       "584177  2013-04-11   Bullish  \n",
       "584178  2013-04-11   Bullish  \n",
       "584179  2013-04-11            \n",
       "584180  2013-04-11            "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10bed10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data within the specified date range\n",
    "start_date = '2020-06-01'\n",
    "end_date = '2022-02-28'\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "filtered_df = df[(df['time'] >= start_date) & (df['time'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85ea6ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439881211</td>\n",
       "      <td>$NVDA I see a 20 $ move to the upside</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439881067</td>\n",
       "      <td>$NVDA holding 💎📈</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439880835</td>\n",
       "      <td>$NVDA  about to moon … again</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439880275</td>\n",
       "      <td>$NVDA got some calls for a few weeks out and s...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439879846</td>\n",
       "      <td>$NVDA I’m buying this it looks like bottom</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text       time  \\\n",
       "0  439881211              $NVDA I see a 20 $ move to the upside 2022-02-28   \n",
       "1  439881067                                   $NVDA holding 💎📈 2022-02-28   \n",
       "2  439880835                       $NVDA  about to moon … again 2022-02-28   \n",
       "3  439880275  $NVDA got some calls for a few weeks out and s... 2022-02-28   \n",
       "4  439879846         $NVDA I’m buying this it looks like bottom 2022-02-28   \n",
       "\n",
       "  sentiment  \n",
       "0   Bullish  \n",
       "1   Bullish  \n",
       "2   Bullish  \n",
       "3   Bullish  \n",
       "4   Bullish  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48ce00f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224941</th>\n",
       "      <td>216124041</td>\n",
       "      <td>$SHOP $NVDA $BYND $SPY  i want $W tooo</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224942</th>\n",
       "      <td>216123311</td>\n",
       "      <td>$NVDA $370 Eow</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224943</th>\n",
       "      <td>216118763</td>\n",
       "      <td>$SPY $GILD $BABA $AAPL $NVDA “Pandemic” + full...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224944</th>\n",
       "      <td>216114459</td>\n",
       "      <td>$NVDA going to new highs soon</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224945</th>\n",
       "      <td>216113684</td>\n",
       "      <td>$NVDA Nasdaq will be green by 3AM. Brrrrrrrr.....</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "224941  216124041             $SHOP $NVDA $BYND $SPY  i want $W tooo   \n",
       "224942  216123311                                     $NVDA $370 Eow   \n",
       "224943  216118763  $SPY $GILD $BABA $AAPL $NVDA “Pandemic” + full...   \n",
       "224944  216114459                      $NVDA going to new highs soon   \n",
       "224945  216113684  $NVDA Nasdaq will be green by 3AM. Brrrrrrrr.....   \n",
       "\n",
       "             time sentiment  \n",
       "224941 2020-06-01            \n",
       "224942 2020-06-01            \n",
       "224943 2020-06-01   Bullish  \n",
       "224944 2020-06-01   Bullish  \n",
       "224945 2020-06-01            "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3076f362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\NVDA\\NVDA_2013_2022\\Nvidia_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the filtered DataFrame as a CSV file\n",
    "output_file = r'C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\NVDA\\NVDA_2013_2022\\Nvidia_1.csv'  \n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'Filtered data saved to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0cfb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\NVDA\\NVDA_2013_2022\\Nvidia_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eba29494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224941</th>\n",
       "      <td>216124041</td>\n",
       "      <td>$SHOP $NVDA $BYND $SPY  i want $W tooo</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224942</th>\n",
       "      <td>216123311</td>\n",
       "      <td>$NVDA $370 Eow</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224943</th>\n",
       "      <td>216118763</td>\n",
       "      <td>$SPY $GILD $BABA $AAPL $NVDA “Pandemic” + full...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224944</th>\n",
       "      <td>216114459</td>\n",
       "      <td>$NVDA going to new highs soon</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224945</th>\n",
       "      <td>216113684</td>\n",
       "      <td>$NVDA Nasdaq will be green by 3AM. Brrrrrrrr.....</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "224941  216124041             $SHOP $NVDA $BYND $SPY  i want $W tooo   \n",
       "224942  216123311                                     $NVDA $370 Eow   \n",
       "224943  216118763  $SPY $GILD $BABA $AAPL $NVDA “Pandemic” + full...   \n",
       "224944  216114459                      $NVDA going to new highs soon   \n",
       "224945  216113684  $NVDA Nasdaq will be green by 3AM. Brrrrrrrr.....   \n",
       "\n",
       "              time sentiment  \n",
       "224941  2020-06-01       NaN  \n",
       "224942  2020-06-01       NaN  \n",
       "224943  2020-06-01   Bullish  \n",
       "224944  2020-06-01   Bullish  \n",
       "224945  2020-06-01       NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e470472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bf4e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe4a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8e8d33cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_1\\sorted_Nvidia_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97b7686c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439881211</td>\n",
       "      <td>$NVDA I see a 20 $ move to the upside</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439881067</td>\n",
       "      <td>$NVDA holding 💎📈</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439880835</td>\n",
       "      <td>$NVDA  about to moon … again</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439880275</td>\n",
       "      <td>$NVDA got some calls for a few weeks out and s...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439879846</td>\n",
       "      <td>$NVDA I’m buying this it looks like bottom</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text        time  \\\n",
       "0  439881211              $NVDA I see a 20 $ move to the upside  2022-02-28   \n",
       "1  439881067                                   $NVDA holding 💎📈  2022-02-28   \n",
       "2  439880835                       $NVDA  about to moon … again  2022-02-28   \n",
       "3  439880275  $NVDA got some calls for a few weeks out and s...  2022-02-28   \n",
       "4  439879846         $NVDA I’m buying this it looks like bottom  2022-02-28   \n",
       "\n",
       "  sentiment  \n",
       "0   Bullish  \n",
       "1   Bullish  \n",
       "2   Bullish  \n",
       "3   Bullish  \n",
       "4   Bullish  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4304c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224941</th>\n",
       "      <td>216124041</td>\n",
       "      <td>$SHOP $NVDA $BYND $SPY  i want $W tooo</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224942</th>\n",
       "      <td>216123311</td>\n",
       "      <td>$NVDA $370 Eow</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224943</th>\n",
       "      <td>216118763</td>\n",
       "      <td>$SPY $GILD $BABA $AAPL $NVDA “Pandemic” + full...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224944</th>\n",
       "      <td>216114459</td>\n",
       "      <td>$NVDA going to new highs soon</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224945</th>\n",
       "      <td>216113684</td>\n",
       "      <td>$NVDA Nasdaq will be green by 3AM. Brrrrrrrr.....</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "224941  216124041             $SHOP $NVDA $BYND $SPY  i want $W tooo   \n",
       "224942  216123311                                     $NVDA $370 Eow   \n",
       "224943  216118763  $SPY $GILD $BABA $AAPL $NVDA “Pandemic” + full...   \n",
       "224944  216114459                      $NVDA going to new highs soon   \n",
       "224945  216113684  $NVDA Nasdaq will be green by 3AM. Brrrrrrrr.....   \n",
       "\n",
       "              time sentiment  \n",
       "224941  2020-06-01       NaN  \n",
       "224942  2020-06-01       NaN  \n",
       "224943  2020-06-01   Bullish  \n",
       "224944  2020-06-01   Bullish  \n",
       "224945  2020-06-01       NaN  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5b931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4db01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59fa49cc",
   "metadata": {},
   "source": [
    "# Sort dates in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c92ccbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted data saved to C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_1\\sorted_Nvidia_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = r'C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_1\\sorted_Nvidia_1.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Convert the 'time' column to datetime format with the new format\n",
    "data['time'] = pd.to_datetime(data['time'], format='%Y-%m-%d').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Sort the DataFrame by the 'time' column in ascending order\n",
    "data = data.sort_values(by='time')\n",
    "\n",
    "# Save the sorted DataFrame to a new CSV file\n",
    "sorted_csv_file_path = r'C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_1\\sorted_Nvidia_1.csv'\n",
    "data.to_csv(sorted_csv_file_path, index=False)\n",
    "\n",
    "print(f'Sorted data saved to {sorted_csv_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db9f3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_1\\sorted_Nvidia_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "88d38216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216113684</td>\n",
       "      <td>$NVDA Nasdaq will be green by 3AM. Brrrrrrrr.....</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216269957</td>\n",
       "      <td>$NVDA those 400 calls for next week aren&amp;#39;t...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216268160</td>\n",
       "      <td>@jensonlaw lol $QQQ up 13% in the last 3 month...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>216266036</td>\n",
       "      <td>$NVDA still holding this name watching 355 are...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>216262159</td>\n",
       "      <td>$NVDA  weekly *almost* giving a big sell signa...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text        time  \\\n",
       "0  216113684  $NVDA Nasdaq will be green by 3AM. Brrrrrrrr.....  2020-06-01   \n",
       "1  216269957  $NVDA those 400 calls for next week aren&#39;t...  2020-06-01   \n",
       "2  216268160  @jensonlaw lol $QQQ up 13% in the last 3 month...  2020-06-01   \n",
       "3  216266036  $NVDA still holding this name watching 355 are...  2020-06-01   \n",
       "4  216262159  $NVDA  weekly *almost* giving a big sell signa...  2020-06-01   \n",
       "\n",
       "  sentiment  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a837497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224941</th>\n",
       "      <td>439808681</td>\n",
       "      <td>https://youtube.com/watch?v=Tfp63bYqr_s&amp;amp;fe...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224942</th>\n",
       "      <td>439809197</td>\n",
       "      <td>$NVDA Futures are tanking - as you all know.  ...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224943</th>\n",
       "      <td>439809385</td>\n",
       "      <td>$NVDA good times coming to add to the position...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224944</th>\n",
       "      <td>439805726</td>\n",
       "      <td>$NVDA Volatility is King!! Simulated Weekly $2...</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224945</th>\n",
       "      <td>439881211</td>\n",
       "      <td>$NVDA I see a 20 $ move to the upside</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>Bullish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "224941  439808681  https://youtube.com/watch?v=Tfp63bYqr_s&amp;fe...   \n",
       "224942  439809197  $NVDA Futures are tanking - as you all know.  ...   \n",
       "224943  439809385  $NVDA good times coming to add to the position...   \n",
       "224944  439805726  $NVDA Volatility is King!! Simulated Weekly $2...   \n",
       "224945  439881211              $NVDA I see a 20 $ move to the upside   \n",
       "\n",
       "              time sentiment  \n",
       "224941  2022-02-28       NaN  \n",
       "224942  2022-02-28   Bullish  \n",
       "224943  2022-02-28   Bullish  \n",
       "224944  2022-02-28       NaN  \n",
       "224945  2022-02-28   Bullish  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fac864d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224946"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_1\\sorted_Nvidia_1.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9186f682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90327"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_2\\sorted_Nvidia_2.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c3dab1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100226"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\sahma\\Desktop\\Thises\\Stocks\\stocks\\NVDA\\NVDA_3\\sorted_Nvidia_3.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af422f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f1564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
